{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ROC_curve.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNFLjYlTgeiH1mMgdU8LY5J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IT-17005/Schizophrenia/blob/main/ROC_curve.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PZNMgps9_Iyq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import ipywidgets as widgets\n",
        "import io\n",
        "from PIL import Image\n",
        "from IPython.display import display,clear_output\n",
        "from warnings import filterwarnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SirXNPr3_f8N",
        "outputId": "497ff5f4-5930-4ac4-bbe2-c16f9afc3d2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['non-scz','scz']"
      ],
      "metadata": {
        "id": "l1kLty_E_21x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "image_size = 224\n",
        "for i in labels:\n",
        "    folderPath = os.path.join('/content/gdrive/MyDrive/SchiFinalDataset','train',i)\n",
        "    for j in tqdm(os.listdir(folderPath)):\n",
        "        img = cv2.imread(os.path.join(folderPath,j))\n",
        "        img = cv2.resize(img,(image_size, image_size))\n",
        "        X_train.append(img)\n",
        "        y_train.append(i)\n",
        "        \n",
        "for i in labels:\n",
        "    folderPath = os.path.join('/content/gdrive/MyDrive/SchiFinalDataset','val',i)\n",
        "    for j in tqdm(os.listdir(folderPath)):\n",
        "        img = cv2.imread(os.path.join(folderPath,j))\n",
        "        img = cv2.resize(img,(image_size,image_size))\n",
        "        X_train.append(img)\n",
        "        y_train.append(i)\n",
        "        \n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzqZWzOI_vyQ",
        "outputId": "38a81a83-4c60-455e-cf93-439816e7e518"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1400/1400 [00:06<00:00, 233.13it/s]\n",
            "100%|██████████| 1120/1120 [00:27<00:00, 40.85it/s] \n",
            "100%|██████████| 400/400 [00:07<00:00, 55.81it/s] \n",
            "100%|██████████| 320/320 [00:06<00:00, 52.40it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = shuffle(X_train,y_train, random_state=101)"
      ],
      "metadata": {
        "id": "EIeso4YLBAtE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFW9DoAcBEHJ",
        "outputId": "e67e5e96-a9f0-4a95-e689-a7fc25eb9db2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3240, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.2,random_state=101)"
      ],
      "metadata": {
        "id": "WGNySMb_BKDC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_new = []\n",
        "for i in y_train:\n",
        "    y_train_new.append(labels.index(i))\n",
        "y_train = y_train_new\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "\n",
        "\n",
        "y_test_new = []\n",
        "for i in y_test:\n",
        "    y_test_new.append(labels.index(i))\n",
        "y_test = y_test_new\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "-V8cqIUIBMHm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "vgg16 = VGG16(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "vgg19 = VGG19(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "efficientnet = tf.keras.applications.EfficientNetB0(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "inceptionv3 = tf.keras.applications.InceptionV3(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "resnet50 = ResNet50(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYo65QklCKUc",
        "outputId": "af540f25-ae99-49f5-96e8-aa23ff509e75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 0s 0us/step\n",
            "80150528/80134624 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n",
            "87924736/87910968 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input,Dense\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size,image_size,3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "R61IYZ5Vr-BG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "model_vgg16 = vgg16.output\n",
        "model_vgg16 = tf.keras.layers.GlobalAveragePooling2D()(model_vgg16)\n",
        "model_vgg16 = tf.keras.layers.Dropout(rate=0.5)(model_vgg16)\n",
        "model_vgg16 = tf.keras.layers.Dense(2,activation='softmax')(model_vgg16)\n",
        "model_vgg16 = tf.keras.models.Model(inputs=vgg16.input, outputs = model_vgg16)\n",
        "model_vgg16.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"vgg16.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_vgg16.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu-DtmCQFgen",
        "outputId": "b37a6930-8834-4391-916d-3f9fb2b2dc77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.8116 - accuracy: 0.5330\n",
            "Epoch 1: val_accuracy improved from -inf to 0.63077, saving model to vgg16.h5\n",
            "73/73 [==============================] - 28s 202ms/step - loss: 2.8116 - accuracy: 0.5330 - val_loss: 0.8285 - val_accuracy: 0.6308 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.6333 - accuracy: 0.5840\n",
            "Epoch 2: val_accuracy improved from 0.63077 to 0.73462, saving model to vgg16.h5\n",
            "73/73 [==============================] - 12s 158ms/step - loss: 1.6333 - accuracy: 0.5840 - val_loss: 0.6144 - val_accuracy: 0.7346 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0593 - accuracy: 0.6321\n",
            "Epoch 3: val_accuracy did not improve from 0.73462\n",
            "73/73 [==============================] - 12s 159ms/step - loss: 1.0593 - accuracy: 0.6321 - val_loss: 0.5782 - val_accuracy: 0.7115 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8030 - accuracy: 0.6685\n",
            "Epoch 4: val_accuracy improved from 0.73462 to 0.78077, saving model to vgg16.h5\n",
            "73/73 [==============================] - 12s 162ms/step - loss: 0.8030 - accuracy: 0.6685 - val_loss: 0.4630 - val_accuracy: 0.7808 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6536 - accuracy: 0.7097\n",
            "Epoch 5: val_accuracy improved from 0.78077 to 0.81923, saving model to vgg16.h5\n",
            "73/73 [==============================] - 12s 161ms/step - loss: 0.6536 - accuracy: 0.7097 - val_loss: 0.4226 - val_accuracy: 0.8192 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6294 - accuracy: 0.7153\n",
            "Epoch 6: val_accuracy did not improve from 0.81923\n",
            "73/73 [==============================] - 12s 160ms/step - loss: 0.6294 - accuracy: 0.7153 - val_loss: 0.4389 - val_accuracy: 0.8115 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.7496\n",
            "Epoch 7: val_accuracy did not improve from 0.81923\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 12s 164ms/step - loss: 0.5427 - accuracy: 0.7496 - val_loss: 0.4070 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.7646\n",
            "Epoch 8: val_accuracy improved from 0.81923 to 0.83846, saving model to vgg16.h5\n",
            "73/73 [==============================] - 12s 166ms/step - loss: 0.5104 - accuracy: 0.7646 - val_loss: 0.3923 - val_accuracy: 0.8385 - lr: 4.0000e-04\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5049 - accuracy: 0.7526\n",
            "Epoch 9: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 166ms/step - loss: 0.5049 - accuracy: 0.7526 - val_loss: 0.4269 - val_accuracy: 0.8269 - lr: 4.0000e-04\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.7577\n",
            "Epoch 10: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 12s 162ms/step - loss: 0.5050 - accuracy: 0.7577 - val_loss: 0.3951 - val_accuracy: 0.8231 - lr: 4.0000e-04\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4781 - accuracy: 0.7766\n",
            "Epoch 11: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 164ms/step - loss: 0.4781 - accuracy: 0.7766 - val_loss: 0.3973 - val_accuracy: 0.8231 - lr: 1.6000e-04\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.7650\n",
            "Epoch 12: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 12s 165ms/step - loss: 0.4844 - accuracy: 0.7650 - val_loss: 0.4117 - val_accuracy: 0.8269 - lr: 1.6000e-04\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4865 - accuracy: 0.7693\n",
            "Epoch 13: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 165ms/step - loss: 0.4865 - accuracy: 0.7693 - val_loss: 0.4012 - val_accuracy: 0.8192 - lr: 6.4000e-05\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.7684\n",
            "Epoch 14: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
            "73/73 [==============================] - 12s 166ms/step - loss: 0.4849 - accuracy: 0.7684 - val_loss: 0.4004 - val_accuracy: 0.8192 - lr: 6.4000e-05\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.7697\n",
            "Epoch 15: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 165ms/step - loss: 0.4742 - accuracy: 0.7697 - val_loss: 0.3977 - val_accuracy: 0.8154 - lr: 2.5600e-05\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.7736\n",
            "Epoch 16: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
            "73/73 [==============================] - 12s 165ms/step - loss: 0.4749 - accuracy: 0.7736 - val_loss: 0.3979 - val_accuracy: 0.8269 - lr: 2.5600e-05\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4699 - accuracy: 0.7710\n",
            "Epoch 17: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 167ms/step - loss: 0.4699 - accuracy: 0.7710 - val_loss: 0.3980 - val_accuracy: 0.8231 - lr: 1.0240e-05\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.7633\n",
            "Epoch 18: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
            "73/73 [==============================] - 12s 166ms/step - loss: 0.4860 - accuracy: 0.7633 - val_loss: 0.3978 - val_accuracy: 0.8231 - lr: 1.0240e-05\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.7830\n",
            "Epoch 19: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 167ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.3977 - val_accuracy: 0.8192 - lr: 4.0960e-06\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.7792\n",
            "Epoch 20: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
            "73/73 [==============================] - 12s 168ms/step - loss: 0.4579 - accuracy: 0.7792 - val_loss: 0.3979 - val_accuracy: 0.8192 - lr: 4.0960e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6d2ec89d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False\n",
        "model_vgg19 = vgg19.output\n",
        "model_vgg19 = tf.keras.layers.GlobalAveragePooling2D()(model_vgg19)\n",
        "model_vgg19 = tf.keras.layers.Dropout(rate=0.5)(model_vgg19)\n",
        "model_vgg19 = tf.keras.layers.Dense(2,activation='softmax')(model_vgg19)\n",
        "model_vgg19 = tf.keras.models.Model(inputs=vgg19.input, outputs = model_vgg19)\n",
        "model_vgg19.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"vgg19.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_vgg19.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSg9aUqVG28y",
        "outputId": "6894bd39-d414-4168-956c-a7f664846463"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.4675 - accuracy: 0.5081\n",
            "Epoch 1: val_accuracy improved from -inf to 0.61154, saving model to vgg19.h5\n",
            "73/73 [==============================] - 15s 200ms/step - loss: 2.4675 - accuracy: 0.5081 - val_loss: 0.8933 - val_accuracy: 0.6115 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.4981 - accuracy: 0.5733\n",
            "Epoch 2: val_accuracy improved from 0.61154 to 0.63462, saving model to vgg19.h5\n",
            "73/73 [==============================] - 14s 198ms/step - loss: 1.4981 - accuracy: 0.5733 - val_loss: 0.6492 - val_accuracy: 0.6346 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9450 - accuracy: 0.6372\n",
            "Epoch 3: val_accuracy improved from 0.63462 to 0.70000, saving model to vgg19.h5\n",
            "73/73 [==============================] - 16s 214ms/step - loss: 0.9450 - accuracy: 0.6372 - val_loss: 0.5498 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7835 - accuracy: 0.6432\n",
            "Epoch 4: val_accuracy improved from 0.70000 to 0.71154, saving model to vgg19.h5\n",
            "73/73 [==============================] - 14s 199ms/step - loss: 0.7835 - accuracy: 0.6432 - val_loss: 0.5179 - val_accuracy: 0.7115 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6740 - accuracy: 0.6938\n",
            "Epoch 5: val_accuracy improved from 0.71154 to 0.75769, saving model to vgg19.h5\n",
            "73/73 [==============================] - 15s 199ms/step - loss: 0.6740 - accuracy: 0.6938 - val_loss: 0.4812 - val_accuracy: 0.7577 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6083 - accuracy: 0.7071\n",
            "Epoch 6: val_accuracy did not improve from 0.75769\n",
            "73/73 [==============================] - 15s 213ms/step - loss: 0.6083 - accuracy: 0.7071 - val_loss: 0.5644 - val_accuracy: 0.6769 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5957 - accuracy: 0.7075\n",
            "Epoch 7: val_accuracy improved from 0.75769 to 0.77308, saving model to vgg19.h5\n",
            "73/73 [==============================] - 15s 200ms/step - loss: 0.5957 - accuracy: 0.7075 - val_loss: 0.4519 - val_accuracy: 0.7731 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5464 - accuracy: 0.7354\n",
            "Epoch 8: val_accuracy did not improve from 0.77308\n",
            "73/73 [==============================] - 16s 213ms/step - loss: 0.5464 - accuracy: 0.7354 - val_loss: 0.4982 - val_accuracy: 0.7615 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5344 - accuracy: 0.7213\n",
            "Epoch 9: val_accuracy improved from 0.77308 to 0.81154, saving model to vgg19.h5\n",
            "73/73 [==============================] - 16s 216ms/step - loss: 0.5344 - accuracy: 0.7213 - val_loss: 0.4398 - val_accuracy: 0.8115 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.7337\n",
            "Epoch 10: val_accuracy improved from 0.81154 to 0.81538, saving model to vgg19.h5\n",
            "73/73 [==============================] - 16s 216ms/step - loss: 0.5501 - accuracy: 0.7337 - val_loss: 0.4494 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.7311\n",
            "Epoch 11: val_accuracy did not improve from 0.81538\n",
            "73/73 [==============================] - 14s 198ms/step - loss: 0.5620 - accuracy: 0.7311 - val_loss: 0.4554 - val_accuracy: 0.7731 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.7393\n",
            "Epoch 12: val_accuracy did not improve from 0.81538\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 16s 214ms/step - loss: 0.5298 - accuracy: 0.7393 - val_loss: 0.4791 - val_accuracy: 0.7769 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.7642\n",
            "Epoch 13: val_accuracy improved from 0.81538 to 0.83077, saving model to vgg19.h5\n",
            "73/73 [==============================] - 15s 202ms/step - loss: 0.5024 - accuracy: 0.7642 - val_loss: 0.4216 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.7543\n",
            "Epoch 14: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 16s 216ms/step - loss: 0.4958 - accuracy: 0.7543 - val_loss: 0.4209 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.7500\n",
            "Epoch 15: val_accuracy improved from 0.83077 to 0.83846, saving model to vgg19.h5\n",
            "73/73 [==============================] - 16s 221ms/step - loss: 0.5084 - accuracy: 0.7500 - val_loss: 0.4300 - val_accuracy: 0.8385 - lr: 4.0000e-04\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.7599\n",
            "Epoch 16: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 15s 204ms/step - loss: 0.4915 - accuracy: 0.7599 - val_loss: 0.4322 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.7496\n",
            "Epoch 17: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 15s 204ms/step - loss: 0.5032 - accuracy: 0.7496 - val_loss: 0.4228 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4937 - accuracy: 0.7629\n",
            "Epoch 18: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 16s 218ms/step - loss: 0.4937 - accuracy: 0.7629 - val_loss: 0.4223 - val_accuracy: 0.8231 - lr: 1.6000e-04\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5008 - accuracy: 0.7667\n",
            "Epoch 19: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 16s 218ms/step - loss: 0.5008 - accuracy: 0.7667 - val_loss: 0.4197 - val_accuracy: 0.8308 - lr: 1.6000e-04\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4887 - accuracy: 0.7611\n",
            "Epoch 20: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 16s 218ms/step - loss: 0.4887 - accuracy: 0.7611 - val_loss: 0.4217 - val_accuracy: 0.8385 - lr: 6.4000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6d2e0dd10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in efficientnet.layers:\n",
        "    layer.trainable = False\n",
        "model_efficientnet = efficientnet.output\n",
        "model_efficientnet = tf.keras.layers.GlobalAveragePooling2D()(model_efficientnet)\n",
        "model_efficientnet = tf.keras.layers.Dropout(rate=0.5)(model_efficientnet)\n",
        "model_efficientnet = tf.keras.layers.Dense(2,activation='softmax')(model_efficientnet)\n",
        "model_efficientnet = tf.keras.models.Model(inputs=efficientnet.input, outputs = model_efficientnet)\n",
        "model_efficientnet.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"efficientnet.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_efficientnet.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psLJGI27q0uH",
        "outputId": "5c59a7b3-8bd6-4a7b-f3dc-4803c3026aa3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7223 - accuracy: 0.5617\n",
            "Epoch 1: val_accuracy improved from -inf to 0.71923, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 14s 109ms/step - loss: 0.7223 - accuracy: 0.5617 - val_loss: 0.5913 - val_accuracy: 0.7192 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5891 - accuracy: 0.6913\n",
            "Epoch 2: val_accuracy did not improve from 0.71923\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.5891 - accuracy: 0.6913 - val_loss: 0.5593 - val_accuracy: 0.6731 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.7230\n",
            "Epoch 3: val_accuracy improved from 0.71923 to 0.74231, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.5486 - accuracy: 0.7230 - val_loss: 0.5108 - val_accuracy: 0.7423 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.7350\n",
            "Epoch 4: val_accuracy improved from 0.74231 to 0.78846, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.5230 - accuracy: 0.7350 - val_loss: 0.4734 - val_accuracy: 0.7885 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5135 - accuracy: 0.7363\n",
            "Epoch 5: val_accuracy improved from 0.78846 to 0.82308, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.5135 - accuracy: 0.7363 - val_loss: 0.4584 - val_accuracy: 0.8231 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.7517\n",
            "Epoch 6: val_accuracy did not improve from 0.82308\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.4974 - accuracy: 0.7517 - val_loss: 0.4580 - val_accuracy: 0.7962 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.7650\n",
            "Epoch 7: val_accuracy did not improve from 0.82308\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.4799 - accuracy: 0.7650 - val_loss: 0.4289 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4600 - accuracy: 0.7749\n",
            "Epoch 8: val_accuracy improved from 0.82308 to 0.83077, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.4600 - accuracy: 0.7749 - val_loss: 0.4248 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.7933\n",
            "Epoch 9: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4526 - accuracy: 0.7933 - val_loss: 0.4249 - val_accuracy: 0.8231 - lr: 4.0000e-04\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.7882\n",
            "Epoch 10: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4189 - val_accuracy: 0.8269 - lr: 4.0000e-04\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4610 - accuracy: 0.7882\n",
            "Epoch 11: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4610 - accuracy: 0.7882 - val_loss: 0.4160 - val_accuracy: 0.8308 - lr: 1.6000e-04\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.7946\n",
            "Epoch 12: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4503 - accuracy: 0.7946 - val_loss: 0.4181 - val_accuracy: 0.8192 - lr: 1.6000e-04\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.7834\n",
            "Epoch 13: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4503 - accuracy: 0.7834 - val_loss: 0.4190 - val_accuracy: 0.8115 - lr: 6.4000e-05\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.7907\n",
            "Epoch 14: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.4526 - accuracy: 0.7907 - val_loss: 0.4175 - val_accuracy: 0.8231 - lr: 6.4000e-05\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.7955\n",
            "Epoch 15: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.4443 - accuracy: 0.7955 - val_loss: 0.4166 - val_accuracy: 0.8192 - lr: 2.5600e-05\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.7937\n",
            "Epoch 16: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4468 - accuracy: 0.7937 - val_loss: 0.4153 - val_accuracy: 0.8154 - lr: 2.5600e-05\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.7946\n",
            "Epoch 17: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.4446 - accuracy: 0.7946 - val_loss: 0.4152 - val_accuracy: 0.8154 - lr: 1.0240e-05\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.8032\n",
            "Epoch 18: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.4292 - accuracy: 0.8032 - val_loss: 0.4148 - val_accuracy: 0.8154 - lr: 1.0240e-05\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.7916\n",
            "Epoch 19: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4505 - accuracy: 0.7916 - val_loss: 0.4148 - val_accuracy: 0.8154 - lr: 4.0960e-06\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4445 - accuracy: 0.7899\n",
            "Epoch 20: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4445 - accuracy: 0.7899 - val_loss: 0.4149 - val_accuracy: 0.8154 - lr: 4.0960e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6d2b68950>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in inceptionv3.layers:\n",
        "    layer.trainable = False\n",
        "model_inceptionv3 = inceptionv3.output\n",
        "model_inceptionv3 = tf.keras.layers.GlobalAveragePooling2D()(model_inceptionv3)\n",
        "model_inceptionv3 = tf.keras.layers.Dropout(rate=0.5)(model_inceptionv3)\n",
        "model_inceptionv3 = tf.keras.layers.Dense(2,activation='softmax')(model_inceptionv3)\n",
        "model_inceptionv3 = tf.keras.models.Model(inputs=inceptionv3.input, outputs = model_inceptionv3)\n",
        "model_inceptionv3.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"inceptionv3.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_inceptionv3.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o408EPZrs5gm",
        "outputId": "36d2d132-f554-41ca-e7be-d75980afb4e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 10.1004 - accuracy: 0.5180\n",
            "Epoch 1: val_accuracy improved from -inf to 0.63077, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 14s 127ms/step - loss: 10.1004 - accuracy: 0.5180 - val_loss: 2.0707 - val_accuracy: 0.6308 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 4.6128 - accuracy: 0.6141\n",
            "Epoch 2: val_accuracy improved from 0.63077 to 0.75385, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 4.6128 - accuracy: 0.6141 - val_loss: 1.5935 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 3.2126 - accuracy: 0.6621\n",
            "Epoch 3: val_accuracy improved from 0.75385 to 0.77692, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 3.2126 - accuracy: 0.6621 - val_loss: 1.1248 - val_accuracy: 0.7769 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.1227 - accuracy: 0.7028\n",
            "Epoch 4: val_accuracy improved from 0.77692 to 0.79231, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 2.1227 - accuracy: 0.7028 - val_loss: 0.9429 - val_accuracy: 0.7923 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.1342 - accuracy: 0.6930\n",
            "Epoch 5: val_accuracy did not improve from 0.79231\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 2.1342 - accuracy: 0.6930 - val_loss: 2.6305 - val_accuracy: 0.6731 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.1651 - accuracy: 0.6925\n",
            "Epoch 6: val_accuracy improved from 0.79231 to 0.81154, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 2.1651 - accuracy: 0.6925 - val_loss: 0.8691 - val_accuracy: 0.8115 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.0398 - accuracy: 0.7093\n",
            "Epoch 7: val_accuracy improved from 0.81154 to 0.81538, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 2.0398 - accuracy: 0.7093 - val_loss: 0.7185 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.6486 - accuracy: 0.7281\n",
            "Epoch 8: val_accuracy improved from 0.81538 to 0.83077, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 7s 89ms/step - loss: 1.6486 - accuracy: 0.7281 - val_loss: 0.5444 - val_accuracy: 0.8308 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.5750 - accuracy: 0.7196\n",
            "Epoch 9: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 1.5750 - accuracy: 0.7196 - val_loss: 0.7188 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.4423 - accuracy: 0.7226\n",
            "Epoch 10: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 1.4423 - accuracy: 0.7226 - val_loss: 1.3084 - val_accuracy: 0.6923 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.1886 - accuracy: 0.7479\n",
            "Epoch 11: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 1.1886 - accuracy: 0.7479 - val_loss: 0.7000 - val_accuracy: 0.7885 - lr: 4.0000e-04\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.1234 - accuracy: 0.7547\n",
            "Epoch 12: val_accuracy improved from 0.83077 to 0.85385, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 1.1234 - accuracy: 0.7547 - val_loss: 0.4603 - val_accuracy: 0.8538 - lr: 4.0000e-04\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0908 - accuracy: 0.7513\n",
            "Epoch 13: val_accuracy did not improve from 0.85385\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 1.0908 - accuracy: 0.7513 - val_loss: 0.3671 - val_accuracy: 0.8538 - lr: 4.0000e-04\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0271 - accuracy: 0.7581\n",
            "Epoch 14: val_accuracy did not improve from 0.85385\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 1.0271 - accuracy: 0.7581 - val_loss: 0.6254 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8214 - accuracy: 0.7834\n",
            "Epoch 15: val_accuracy did not improve from 0.85385\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.8214 - accuracy: 0.7834 - val_loss: 0.7337 - val_accuracy: 0.8115 - lr: 1.6000e-04\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8881 - accuracy: 0.7684\n",
            "Epoch 16: val_accuracy did not improve from 0.85385\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.8881 - accuracy: 0.7684 - val_loss: 0.3866 - val_accuracy: 0.8385 - lr: 1.6000e-04\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.7796\n",
            "Epoch 17: val_accuracy improved from 0.85385 to 0.86923, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.8372 - accuracy: 0.7796 - val_loss: 0.3420 - val_accuracy: 0.8692 - lr: 6.4000e-05\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7896 - accuracy: 0.7903\n",
            "Epoch 18: val_accuracy did not improve from 0.86923\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.7896 - accuracy: 0.7903 - val_loss: 0.3678 - val_accuracy: 0.8538 - lr: 6.4000e-05\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7672 - accuracy: 0.7907\n",
            "Epoch 19: val_accuracy did not improve from 0.86923\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.7672 - accuracy: 0.7907 - val_loss: 0.3184 - val_accuracy: 0.8692 - lr: 6.4000e-05\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7944 - accuracy: 0.7766\n",
            "Epoch 20: val_accuracy improved from 0.86923 to 0.87308, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 0.7944 - accuracy: 0.7766 - val_loss: 0.3203 - val_accuracy: 0.8731 - lr: 2.5600e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd68e49f8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in resnet50.layers:\n",
        "    layer.trainable = False\n",
        "model_resnet50 = resnet50.output\n",
        "model_resnet50 = tf.keras.layers.GlobalAveragePooling2D()(model_resnet50)\n",
        "model_resnet50 = tf.keras.layers.Dropout(rate=0.5)(model_resnet50)\n",
        "model_resnet50 = tf.keras.layers.Dense(2,activation='softmax')(model_resnet50)\n",
        "model_resnet50 = tf.keras.models.Model(inputs=resnet50.input, outputs = model_resnet50)\n",
        "model_resnet50.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"resnet50.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_resnet50.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeMOuAdkqN55",
        "outputId": "90038d10-fb9b-4fe1-a35e-7d8fe7142204"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8851 - accuracy: 0.5828\n",
            "Epoch 1: val_accuracy improved from -inf to 0.67308, saving model to resnet50.h5\n",
            "73/73 [==============================] - 14s 137ms/step - loss: 0.8851 - accuracy: 0.5828 - val_loss: 0.5593 - val_accuracy: 0.6731 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.6801\n",
            "Epoch 2: val_accuracy improved from 0.67308 to 0.80769, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 109ms/step - loss: 0.6249 - accuracy: 0.6801 - val_loss: 0.4318 - val_accuracy: 0.8077 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5410 - accuracy: 0.7324\n",
            "Epoch 3: val_accuracy improved from 0.80769 to 0.84231, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 110ms/step - loss: 0.5410 - accuracy: 0.7324 - val_loss: 0.3923 - val_accuracy: 0.8423 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4779 - accuracy: 0.7714\n",
            "Epoch 4: val_accuracy improved from 0.84231 to 0.86154, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 117ms/step - loss: 0.4779 - accuracy: 0.7714 - val_loss: 0.3744 - val_accuracy: 0.8615 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.7783\n",
            "Epoch 5: val_accuracy improved from 0.86154 to 0.87692, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 111ms/step - loss: 0.4601 - accuracy: 0.7783 - val_loss: 0.3414 - val_accuracy: 0.8769 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.7993\n",
            "Epoch 6: val_accuracy improved from 0.87692 to 0.88846, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 118ms/step - loss: 0.4367 - accuracy: 0.7993 - val_loss: 0.3246 - val_accuracy: 0.8885 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.8130\n",
            "Epoch 7: val_accuracy improved from 0.88846 to 0.89615, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 118ms/step - loss: 0.4036 - accuracy: 0.8130 - val_loss: 0.3202 - val_accuracy: 0.8962 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4146 - accuracy: 0.8139\n",
            "Epoch 8: val_accuracy did not improve from 0.89615\n",
            "73/73 [==============================] - 8s 103ms/step - loss: 0.4146 - accuracy: 0.8139 - val_loss: 0.3485 - val_accuracy: 0.8500 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8199\n",
            "Epoch 9: val_accuracy improved from 0.89615 to 0.90000, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 110ms/step - loss: 0.3903 - accuracy: 0.8199 - val_loss: 0.3061 - val_accuracy: 0.9000 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3769 - accuracy: 0.8246\n",
            "Epoch 10: val_accuracy did not improve from 0.90000\n",
            "73/73 [==============================] - 8s 111ms/step - loss: 0.3769 - accuracy: 0.8246 - val_loss: 0.3261 - val_accuracy: 0.8962 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8195\n",
            "Epoch 11: val_accuracy improved from 0.90000 to 0.90769, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 110ms/step - loss: 0.3779 - accuracy: 0.8195 - val_loss: 0.2878 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.8319\n",
            "Epoch 12: val_accuracy did not improve from 0.90769\n",
            "73/73 [==============================] - 8s 104ms/step - loss: 0.3785 - accuracy: 0.8319 - val_loss: 0.2944 - val_accuracy: 0.8808 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3529 - accuracy: 0.8473\n",
            "Epoch 13: val_accuracy did not improve from 0.90769\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 8s 111ms/step - loss: 0.3529 - accuracy: 0.8473 - val_loss: 0.2839 - val_accuracy: 0.9000 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.8572\n",
            "Epoch 14: val_accuracy did not improve from 0.90769\n",
            "73/73 [==============================] - 8s 103ms/step - loss: 0.3464 - accuracy: 0.8572 - val_loss: 0.2792 - val_accuracy: 0.9000 - lr: 4.0000e-04\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.8426\n",
            "Epoch 15: val_accuracy improved from 0.90769 to 0.91538, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 117ms/step - loss: 0.3505 - accuracy: 0.8426 - val_loss: 0.2657 - val_accuracy: 0.9154 - lr: 4.0000e-04\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3323 - accuracy: 0.8559\n",
            "Epoch 16: val_accuracy did not improve from 0.91538\n",
            "73/73 [==============================] - 8s 103ms/step - loss: 0.3323 - accuracy: 0.8559 - val_loss: 0.2612 - val_accuracy: 0.9154 - lr: 4.0000e-04\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.8461\n",
            "Epoch 17: val_accuracy improved from 0.91538 to 0.91923, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 118ms/step - loss: 0.3462 - accuracy: 0.8461 - val_loss: 0.2629 - val_accuracy: 0.9192 - lr: 4.0000e-04\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8461\n",
            "Epoch 18: val_accuracy did not improve from 0.91923\n",
            "73/73 [==============================] - 8s 104ms/step - loss: 0.3434 - accuracy: 0.8461 - val_loss: 0.2704 - val_accuracy: 0.9000 - lr: 4.0000e-04\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.8533\n",
            "Epoch 19: val_accuracy did not improve from 0.91923\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 8s 104ms/step - loss: 0.3389 - accuracy: 0.8533 - val_loss: 0.2603 - val_accuracy: 0.9192 - lr: 4.0000e-04\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.8563\n",
            "Epoch 20: val_accuracy improved from 0.91923 to 0.92308, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 118ms/step - loss: 0.3333 - accuracy: 0.8563 - val_loss: 0.2622 - val_accuracy: 0.9231 - lr: 1.6000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd5d64c5b50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"ourmodel.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsVTnwPyuh02",
        "outputId": "1458bfad-e11d-4885-e34c-fa1a9c3476f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 30.8165 - accuracy: 0.7714\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89231, saving model to ourmodel.h5\n",
            "73/73 [==============================] - 7s 71ms/step - loss: 30.8165 - accuracy: 0.7714 - val_loss: 0.2406 - val_accuracy: 0.8923 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9443\n",
            "Epoch 2: val_accuracy improved from 0.89231 to 0.98077, saving model to ourmodel.h5\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.1432 - accuracy: 0.9443 - val_loss: 0.0782 - val_accuracy: 0.9808 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9727\n",
            "Epoch 3: val_accuracy improved from 0.98077 to 0.99615, saving model to ourmodel.h5\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.0758 - accuracy: 0.9721 - val_loss: 0.0353 - val_accuracy: 0.9962 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0452 - accuracy: 0.9848\n",
            "Epoch 4: val_accuracy did not improve from 0.99615\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0451 - accuracy: 0.9850 - val_loss: 0.0479 - val_accuracy: 0.9769 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9926\n",
            "Epoch 5: val_accuracy did not improve from 0.99615\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.0151 - val_accuracy: 0.9962 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9979\n",
            "Epoch 6: val_accuracy improved from 0.99615 to 1.00000, saving model to ourmodel.h5\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0067 - val_accuracy: 1.0000 - lr: 4.0000e-04\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9962 - lr: 4.0000e-04\n",
            "Epoch 8/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9983\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.0108 - val_accuracy: 0.9962 - lr: 4.0000e-04\n",
            "Epoch 9/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000 - lr: 1.6000e-04\n",
            "Epoch 10/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - lr: 1.6000e-04\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 6.4000e-05\n",
            "Epoch 12/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 6.4000e-05\n",
            "Epoch 13/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9996\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 2.5600e-05\n",
            "Epoch 14/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 2.5600e-05\n",
            "Epoch 15/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.0240e-05\n",
            "Epoch 16/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.0240e-05\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 4.0960e-06\n",
            "Epoch 18/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 9.8671e-04 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 9.7514e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 4.0960e-06\n",
            "Epoch 19/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.6384e-06\n",
            "Epoch 20/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 9.1687e-04 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.553600542247295e-07.\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 9.0920e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.6384e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd5d6171f50>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict probabilities\n",
        "pred_prob1 = model_vgg16.predict(X_test)\n",
        "pred_prob2 = model_vgg19.predict(X_test)\n",
        "pred_prob3 = model_efficientnet.predict(X_test)\n",
        "pred_prob4 = model_inceptionv3.predict(X_test)\n",
        "pred_prob5 = model_resnet50.predict(X_test)\n",
        "pred_prob6 = model.predict(X_test)"
      ],
      "metadata": {
        "id": "JSB7eoLbHss9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.argmax(y_test,axis=1)"
      ],
      "metadata": {
        "id": "za-Vz4zK3Pbz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# roc curve for models\n",
        "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\n",
        "fpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2[:,1], pos_label=1)\n",
        "fpr3, tpr3, thresh3 = roc_curve(y_test, pred_prob3[:,1], pos_label=1)\n",
        "fpr4, tpr4, thresh4 = roc_curve(y_test, pred_prob4[:,1], pos_label=1)\n",
        "fpr5, tpr5, thresh5 = roc_curve(y_test, pred_prob5[:,1], pos_label=1)\n",
        "fpr6, tpr6, thresh6 = roc_curve(y_test, pred_prob6[:,1], pos_label=1)\n",
        "\n",
        "# roc curve for tpr = fpr \n",
        "random_probs = [0 for i in range(len(y_test))]\n",
        "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
      ],
      "metadata": {
        "id": "pl_tqxt1M1y6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# auc scores\n",
        "auc_score_vgg16 = roc_auc_score(y_test, pred_prob1[:,1])\n",
        "auc_score_vgg19 = roc_auc_score(y_test, pred_prob2[:,1])\n",
        "auc_score_efficientnet = roc_auc_score(y_test, pred_prob3[:,1])\n",
        "auc_score_inceptionv3 = roc_auc_score(y_test, pred_prob4[:,1])\n",
        "auc_score_resnet50 = roc_auc_score(y_test, pred_prob5[:,1])\n",
        "auc_score_model = roc_auc_score(y_test, pred_prob6[:,1])\n",
        "\n",
        "print(auc_score_vgg16, auc_score_vgg19, auc_score_efficientnet, auc_score_inceptionv3, auc_score_resnet50, auc_score_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENolX_5GRrTE",
        "outputId": "57804270-2213-4ebc-e96d-5fa970238997"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9230399461616112 0.930606162572706 0.9424890640772965 0.9330961880498007 0.9704754122001634 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# plot roc curves\n",
        "plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='VGG-16 (AUC = 0.923)')\n",
        "plt.plot(fpr2, tpr2, linestyle='--',color='green', label='VGG-19 (AUC = 0.930)')\n",
        "plt.plot(fpr3, tpr3, linestyle='--',color='LightSeaGreen', label='EfficientNet (AUC = 0.942)')\n",
        "plt.plot(fpr4, tpr4, linestyle='--',color='lime', label='InceptionV3 (AUC = 0.933)')\n",
        "plt.plot(fpr5, tpr5, linestyle='--',color='purple', label='ResNet50 (AUC = 0.970)')\n",
        "plt.plot(fpr6, tpr6, linestyle='--',color='red', label='OurModel (AUC = 1.0)')\n",
        "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
        "# title\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=14)\n",
        "plt.legend(prop={'size':14}, loc='lower right')\n",
        "# x label\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel('False Positive Rate', fontsize=14)\n",
        "# y label\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel('True Positive rate', fontsize=14)\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('ROC',dpi=300)\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "hWfi5wqBEgNG",
        "outputId": "b2f717c8-855a-4d6b-e2ce-a7775d45de63"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WvpmdasUGxJk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}