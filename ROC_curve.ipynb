{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ROC_curve.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMP8Z+GbwduPuPIxUe55lnv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IT-17005/Schizophrenia/blob/main/ROC_curve.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PZNMgps9_Iyq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import ipywidgets as widgets\n",
        "import io\n",
        "from PIL import Image\n",
        "from IPython.display import display,clear_output\n",
        "from warnings import filterwarnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SirXNPr3_f8N",
        "outputId": "497ff5f4-5930-4ac4-bbe2-c16f9afc3d2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['non-scz','scz']"
      ],
      "metadata": {
        "id": "l1kLty_E_21x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "image_size = 224\n",
        "for i in labels:\n",
        "    folderPath = os.path.join('/content/gdrive/MyDrive/SchiFinalDataset','train',i)\n",
        "    for j in tqdm(os.listdir(folderPath)):\n",
        "        img = cv2.imread(os.path.join(folderPath,j))\n",
        "        img = cv2.resize(img,(image_size, image_size))\n",
        "        X_train.append(img)\n",
        "        y_train.append(i)\n",
        "        \n",
        "for i in labels:\n",
        "    folderPath = os.path.join('/content/gdrive/MyDrive/SchiFinalDataset','val',i)\n",
        "    for j in tqdm(os.listdir(folderPath)):\n",
        "        img = cv2.imread(os.path.join(folderPath,j))\n",
        "        img = cv2.resize(img,(image_size,image_size))\n",
        "        X_train.append(img)\n",
        "        y_train.append(i)\n",
        "        \n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzqZWzOI_vyQ",
        "outputId": "38a81a83-4c60-455e-cf93-439816e7e518"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1400/1400 [00:06<00:00, 233.13it/s]\n",
            "100%|██████████| 1120/1120 [00:27<00:00, 40.85it/s] \n",
            "100%|██████████| 400/400 [00:07<00:00, 55.81it/s] \n",
            "100%|██████████| 320/320 [00:06<00:00, 52.40it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = shuffle(X_train,y_train, random_state=101)"
      ],
      "metadata": {
        "id": "EIeso4YLBAtE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFW9DoAcBEHJ",
        "outputId": "e67e5e96-a9f0-4a95-e689-a7fc25eb9db2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3240, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.2,random_state=101)"
      ],
      "metadata": {
        "id": "WGNySMb_BKDC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_new = []\n",
        "for i in y_train:\n",
        "    y_train_new.append(labels.index(i))\n",
        "y_train = y_train_new\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "\n",
        "\n",
        "y_test_new = []\n",
        "for i in y_test:\n",
        "    y_test_new.append(labels.index(i))\n",
        "y_test = y_test_new\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "-V8cqIUIBMHm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "vgg16 = VGG16(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "vgg19 = VGG19(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "efficientnet = tf.keras.applications.EfficientNetB0(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "inceptionv3 = tf.keras.applications.InceptionV3(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "resnet50 = ResNet50(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYo65QklCKUc",
        "outputId": "af540f25-ae99-49f5-96e8-aa23ff509e75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 0s 0us/step\n",
            "80150528/80134624 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n",
            "87924736/87910968 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input,Dense\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size,image_size,3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "R61IYZ5Vr-BG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "model_vgg16 = vgg16.output\n",
        "model_vgg16 = tf.keras.layers.GlobalAveragePooling2D()(model_vgg16)\n",
        "model_vgg16 = tf.keras.layers.Dropout(rate=0.5)(model_vgg16)\n",
        "model_vgg16 = tf.keras.layers.Dense(2,activation='softmax')(model_vgg16)\n",
        "model_vgg16 = tf.keras.models.Model(inputs=vgg16.input, outputs = model_vgg16)\n",
        "model_vgg16.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"vgg16.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_vgg16.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu-DtmCQFgen",
        "outputId": "b37a6930-8834-4391-916d-3f9fb2b2dc77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.8116 - accuracy: 0.5330\n",
            "Epoch 1: val_accuracy improved from -inf to 0.63077, saving model to vgg16.h5\n",
            "73/73 [==============================] - 28s 202ms/step - loss: 2.8116 - accuracy: 0.5330 - val_loss: 0.8285 - val_accuracy: 0.6308 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.6333 - accuracy: 0.5840\n",
            "Epoch 2: val_accuracy improved from 0.63077 to 0.73462, saving model to vgg16.h5\n",
            "73/73 [==============================] - 12s 158ms/step - loss: 1.6333 - accuracy: 0.5840 - val_loss: 0.6144 - val_accuracy: 0.7346 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0593 - accuracy: 0.6321\n",
            "Epoch 3: val_accuracy did not improve from 0.73462\n",
            "73/73 [==============================] - 12s 159ms/step - loss: 1.0593 - accuracy: 0.6321 - val_loss: 0.5782 - val_accuracy: 0.7115 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8030 - accuracy: 0.6685\n",
            "Epoch 4: val_accuracy improved from 0.73462 to 0.78077, saving model to vgg16.h5\n",
            "73/73 [==============================] - 12s 162ms/step - loss: 0.8030 - accuracy: 0.6685 - val_loss: 0.4630 - val_accuracy: 0.7808 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6536 - accuracy: 0.7097\n",
            "Epoch 5: val_accuracy improved from 0.78077 to 0.81923, saving model to vgg16.h5\n",
            "73/73 [==============================] - 12s 161ms/step - loss: 0.6536 - accuracy: 0.7097 - val_loss: 0.4226 - val_accuracy: 0.8192 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6294 - accuracy: 0.7153\n",
            "Epoch 6: val_accuracy did not improve from 0.81923\n",
            "73/73 [==============================] - 12s 160ms/step - loss: 0.6294 - accuracy: 0.7153 - val_loss: 0.4389 - val_accuracy: 0.8115 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.7496\n",
            "Epoch 7: val_accuracy did not improve from 0.81923\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 12s 164ms/step - loss: 0.5427 - accuracy: 0.7496 - val_loss: 0.4070 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.7646\n",
            "Epoch 8: val_accuracy improved from 0.81923 to 0.83846, saving model to vgg16.h5\n",
            "73/73 [==============================] - 12s 166ms/step - loss: 0.5104 - accuracy: 0.7646 - val_loss: 0.3923 - val_accuracy: 0.8385 - lr: 4.0000e-04\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5049 - accuracy: 0.7526\n",
            "Epoch 9: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 166ms/step - loss: 0.5049 - accuracy: 0.7526 - val_loss: 0.4269 - val_accuracy: 0.8269 - lr: 4.0000e-04\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.7577\n",
            "Epoch 10: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 12s 162ms/step - loss: 0.5050 - accuracy: 0.7577 - val_loss: 0.3951 - val_accuracy: 0.8231 - lr: 4.0000e-04\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4781 - accuracy: 0.7766\n",
            "Epoch 11: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 164ms/step - loss: 0.4781 - accuracy: 0.7766 - val_loss: 0.3973 - val_accuracy: 0.8231 - lr: 1.6000e-04\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.7650\n",
            "Epoch 12: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 12s 165ms/step - loss: 0.4844 - accuracy: 0.7650 - val_loss: 0.4117 - val_accuracy: 0.8269 - lr: 1.6000e-04\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4865 - accuracy: 0.7693\n",
            "Epoch 13: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 165ms/step - loss: 0.4865 - accuracy: 0.7693 - val_loss: 0.4012 - val_accuracy: 0.8192 - lr: 6.4000e-05\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.7684\n",
            "Epoch 14: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
            "73/73 [==============================] - 12s 166ms/step - loss: 0.4849 - accuracy: 0.7684 - val_loss: 0.4004 - val_accuracy: 0.8192 - lr: 6.4000e-05\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.7697\n",
            "Epoch 15: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 165ms/step - loss: 0.4742 - accuracy: 0.7697 - val_loss: 0.3977 - val_accuracy: 0.8154 - lr: 2.5600e-05\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.7736\n",
            "Epoch 16: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
            "73/73 [==============================] - 12s 165ms/step - loss: 0.4749 - accuracy: 0.7736 - val_loss: 0.3979 - val_accuracy: 0.8269 - lr: 2.5600e-05\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4699 - accuracy: 0.7710\n",
            "Epoch 17: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 167ms/step - loss: 0.4699 - accuracy: 0.7710 - val_loss: 0.3980 - val_accuracy: 0.8231 - lr: 1.0240e-05\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.7633\n",
            "Epoch 18: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
            "73/73 [==============================] - 12s 166ms/step - loss: 0.4860 - accuracy: 0.7633 - val_loss: 0.3978 - val_accuracy: 0.8231 - lr: 1.0240e-05\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.7830\n",
            "Epoch 19: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 167ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.3977 - val_accuracy: 0.8192 - lr: 4.0960e-06\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.7792\n",
            "Epoch 20: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
            "73/73 [==============================] - 12s 168ms/step - loss: 0.4579 - accuracy: 0.7792 - val_loss: 0.3979 - val_accuracy: 0.8192 - lr: 4.0960e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6d2ec89d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False\n",
        "model_vgg19 = vgg19.output\n",
        "model_vgg19 = tf.keras.layers.GlobalAveragePooling2D()(model_vgg19)\n",
        "model_vgg19 = tf.keras.layers.Dropout(rate=0.5)(model_vgg19)\n",
        "model_vgg19 = tf.keras.layers.Dense(2,activation='softmax')(model_vgg19)\n",
        "model_vgg19 = tf.keras.models.Model(inputs=vgg19.input, outputs = model_vgg19)\n",
        "model_vgg19.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"vgg19.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_vgg19.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSg9aUqVG28y",
        "outputId": "6894bd39-d414-4168-956c-a7f664846463"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.4675 - accuracy: 0.5081\n",
            "Epoch 1: val_accuracy improved from -inf to 0.61154, saving model to vgg19.h5\n",
            "73/73 [==============================] - 15s 200ms/step - loss: 2.4675 - accuracy: 0.5081 - val_loss: 0.8933 - val_accuracy: 0.6115 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.4981 - accuracy: 0.5733\n",
            "Epoch 2: val_accuracy improved from 0.61154 to 0.63462, saving model to vgg19.h5\n",
            "73/73 [==============================] - 14s 198ms/step - loss: 1.4981 - accuracy: 0.5733 - val_loss: 0.6492 - val_accuracy: 0.6346 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9450 - accuracy: 0.6372\n",
            "Epoch 3: val_accuracy improved from 0.63462 to 0.70000, saving model to vgg19.h5\n",
            "73/73 [==============================] - 16s 214ms/step - loss: 0.9450 - accuracy: 0.6372 - val_loss: 0.5498 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7835 - accuracy: 0.6432\n",
            "Epoch 4: val_accuracy improved from 0.70000 to 0.71154, saving model to vgg19.h5\n",
            "73/73 [==============================] - 14s 199ms/step - loss: 0.7835 - accuracy: 0.6432 - val_loss: 0.5179 - val_accuracy: 0.7115 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6740 - accuracy: 0.6938\n",
            "Epoch 5: val_accuracy improved from 0.71154 to 0.75769, saving model to vgg19.h5\n",
            "73/73 [==============================] - 15s 199ms/step - loss: 0.6740 - accuracy: 0.6938 - val_loss: 0.4812 - val_accuracy: 0.7577 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6083 - accuracy: 0.7071\n",
            "Epoch 6: val_accuracy did not improve from 0.75769\n",
            "73/73 [==============================] - 15s 213ms/step - loss: 0.6083 - accuracy: 0.7071 - val_loss: 0.5644 - val_accuracy: 0.6769 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5957 - accuracy: 0.7075\n",
            "Epoch 7: val_accuracy improved from 0.75769 to 0.77308, saving model to vgg19.h5\n",
            "73/73 [==============================] - 15s 200ms/step - loss: 0.5957 - accuracy: 0.7075 - val_loss: 0.4519 - val_accuracy: 0.7731 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5464 - accuracy: 0.7354\n",
            "Epoch 8: val_accuracy did not improve from 0.77308\n",
            "73/73 [==============================] - 16s 213ms/step - loss: 0.5464 - accuracy: 0.7354 - val_loss: 0.4982 - val_accuracy: 0.7615 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5344 - accuracy: 0.7213\n",
            "Epoch 9: val_accuracy improved from 0.77308 to 0.81154, saving model to vgg19.h5\n",
            "73/73 [==============================] - 16s 216ms/step - loss: 0.5344 - accuracy: 0.7213 - val_loss: 0.4398 - val_accuracy: 0.8115 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.7337\n",
            "Epoch 10: val_accuracy improved from 0.81154 to 0.81538, saving model to vgg19.h5\n",
            "73/73 [==============================] - 16s 216ms/step - loss: 0.5501 - accuracy: 0.7337 - val_loss: 0.4494 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.7311\n",
            "Epoch 11: val_accuracy did not improve from 0.81538\n",
            "73/73 [==============================] - 14s 198ms/step - loss: 0.5620 - accuracy: 0.7311 - val_loss: 0.4554 - val_accuracy: 0.7731 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.7393\n",
            "Epoch 12: val_accuracy did not improve from 0.81538\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 16s 214ms/step - loss: 0.5298 - accuracy: 0.7393 - val_loss: 0.4791 - val_accuracy: 0.7769 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.7642\n",
            "Epoch 13: val_accuracy improved from 0.81538 to 0.83077, saving model to vgg19.h5\n",
            "73/73 [==============================] - 15s 202ms/step - loss: 0.5024 - accuracy: 0.7642 - val_loss: 0.4216 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.7543\n",
            "Epoch 14: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 16s 216ms/step - loss: 0.4958 - accuracy: 0.7543 - val_loss: 0.4209 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.7500\n",
            "Epoch 15: val_accuracy improved from 0.83077 to 0.83846, saving model to vgg19.h5\n",
            "73/73 [==============================] - 16s 221ms/step - loss: 0.5084 - accuracy: 0.7500 - val_loss: 0.4300 - val_accuracy: 0.8385 - lr: 4.0000e-04\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.7599\n",
            "Epoch 16: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 15s 204ms/step - loss: 0.4915 - accuracy: 0.7599 - val_loss: 0.4322 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.7496\n",
            "Epoch 17: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 15s 204ms/step - loss: 0.5032 - accuracy: 0.7496 - val_loss: 0.4228 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4937 - accuracy: 0.7629\n",
            "Epoch 18: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 16s 218ms/step - loss: 0.4937 - accuracy: 0.7629 - val_loss: 0.4223 - val_accuracy: 0.8231 - lr: 1.6000e-04\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5008 - accuracy: 0.7667\n",
            "Epoch 19: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 16s 218ms/step - loss: 0.5008 - accuracy: 0.7667 - val_loss: 0.4197 - val_accuracy: 0.8308 - lr: 1.6000e-04\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4887 - accuracy: 0.7611\n",
            "Epoch 20: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 16s 218ms/step - loss: 0.4887 - accuracy: 0.7611 - val_loss: 0.4217 - val_accuracy: 0.8385 - lr: 6.4000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6d2e0dd10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in efficientnet.layers:\n",
        "    layer.trainable = False\n",
        "model_efficientnet = efficientnet.output\n",
        "model_efficientnet = tf.keras.layers.GlobalAveragePooling2D()(model_efficientnet)\n",
        "model_efficientnet = tf.keras.layers.Dropout(rate=0.5)(model_efficientnet)\n",
        "model_efficientnet = tf.keras.layers.Dense(2,activation='softmax')(model_efficientnet)\n",
        "model_efficientnet = tf.keras.models.Model(inputs=efficientnet.input, outputs = model_efficientnet)\n",
        "model_efficientnet.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"efficientnet.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_efficientnet.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psLJGI27q0uH",
        "outputId": "5c59a7b3-8bd6-4a7b-f3dc-4803c3026aa3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7223 - accuracy: 0.5617\n",
            "Epoch 1: val_accuracy improved from -inf to 0.71923, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 14s 109ms/step - loss: 0.7223 - accuracy: 0.5617 - val_loss: 0.5913 - val_accuracy: 0.7192 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5891 - accuracy: 0.6913\n",
            "Epoch 2: val_accuracy did not improve from 0.71923\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.5891 - accuracy: 0.6913 - val_loss: 0.5593 - val_accuracy: 0.6731 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.7230\n",
            "Epoch 3: val_accuracy improved from 0.71923 to 0.74231, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.5486 - accuracy: 0.7230 - val_loss: 0.5108 - val_accuracy: 0.7423 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.7350\n",
            "Epoch 4: val_accuracy improved from 0.74231 to 0.78846, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.5230 - accuracy: 0.7350 - val_loss: 0.4734 - val_accuracy: 0.7885 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5135 - accuracy: 0.7363\n",
            "Epoch 5: val_accuracy improved from 0.78846 to 0.82308, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.5135 - accuracy: 0.7363 - val_loss: 0.4584 - val_accuracy: 0.8231 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.7517\n",
            "Epoch 6: val_accuracy did not improve from 0.82308\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.4974 - accuracy: 0.7517 - val_loss: 0.4580 - val_accuracy: 0.7962 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.7650\n",
            "Epoch 7: val_accuracy did not improve from 0.82308\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.4799 - accuracy: 0.7650 - val_loss: 0.4289 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4600 - accuracy: 0.7749\n",
            "Epoch 8: val_accuracy improved from 0.82308 to 0.83077, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.4600 - accuracy: 0.7749 - val_loss: 0.4248 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.7933\n",
            "Epoch 9: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4526 - accuracy: 0.7933 - val_loss: 0.4249 - val_accuracy: 0.8231 - lr: 4.0000e-04\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.7882\n",
            "Epoch 10: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4189 - val_accuracy: 0.8269 - lr: 4.0000e-04\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4610 - accuracy: 0.7882\n",
            "Epoch 11: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4610 - accuracy: 0.7882 - val_loss: 0.4160 - val_accuracy: 0.8308 - lr: 1.6000e-04\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.7946\n",
            "Epoch 12: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4503 - accuracy: 0.7946 - val_loss: 0.4181 - val_accuracy: 0.8192 - lr: 1.6000e-04\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.7834\n",
            "Epoch 13: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4503 - accuracy: 0.7834 - val_loss: 0.4190 - val_accuracy: 0.8115 - lr: 6.4000e-05\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.7907\n",
            "Epoch 14: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.4526 - accuracy: 0.7907 - val_loss: 0.4175 - val_accuracy: 0.8231 - lr: 6.4000e-05\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.7955\n",
            "Epoch 15: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.4443 - accuracy: 0.7955 - val_loss: 0.4166 - val_accuracy: 0.8192 - lr: 2.5600e-05\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.7937\n",
            "Epoch 16: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4468 - accuracy: 0.7937 - val_loss: 0.4153 - val_accuracy: 0.8154 - lr: 2.5600e-05\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.7946\n",
            "Epoch 17: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.4446 - accuracy: 0.7946 - val_loss: 0.4152 - val_accuracy: 0.8154 - lr: 1.0240e-05\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.8032\n",
            "Epoch 18: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.4292 - accuracy: 0.8032 - val_loss: 0.4148 - val_accuracy: 0.8154 - lr: 1.0240e-05\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.7916\n",
            "Epoch 19: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4505 - accuracy: 0.7916 - val_loss: 0.4148 - val_accuracy: 0.8154 - lr: 4.0960e-06\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4445 - accuracy: 0.7899\n",
            "Epoch 20: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4445 - accuracy: 0.7899 - val_loss: 0.4149 - val_accuracy: 0.8154 - lr: 4.0960e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6d2b68950>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in inceptionv3.layers:\n",
        "    layer.trainable = False\n",
        "model_inceptionv3 = inceptionv3.output\n",
        "model_inceptionv3 = tf.keras.layers.GlobalAveragePooling2D()(model_inceptionv3)\n",
        "model_inceptionv3 = tf.keras.layers.Dropout(rate=0.5)(model_inceptionv3)\n",
        "model_inceptionv3 = tf.keras.layers.Dense(2,activation='softmax')(model_inceptionv3)\n",
        "model_inceptionv3 = tf.keras.models.Model(inputs=inceptionv3.input, outputs = model_inceptionv3)\n",
        "model_inceptionv3.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"inceptionv3.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_inceptionv3.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o408EPZrs5gm",
        "outputId": "36d2d132-f554-41ca-e7be-d75980afb4e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 10.1004 - accuracy: 0.5180\n",
            "Epoch 1: val_accuracy improved from -inf to 0.63077, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 14s 127ms/step - loss: 10.1004 - accuracy: 0.5180 - val_loss: 2.0707 - val_accuracy: 0.6308 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 4.6128 - accuracy: 0.6141\n",
            "Epoch 2: val_accuracy improved from 0.63077 to 0.75385, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 4.6128 - accuracy: 0.6141 - val_loss: 1.5935 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 3.2126 - accuracy: 0.6621\n",
            "Epoch 3: val_accuracy improved from 0.75385 to 0.77692, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 3.2126 - accuracy: 0.6621 - val_loss: 1.1248 - val_accuracy: 0.7769 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.1227 - accuracy: 0.7028\n",
            "Epoch 4: val_accuracy improved from 0.77692 to 0.79231, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 2.1227 - accuracy: 0.7028 - val_loss: 0.9429 - val_accuracy: 0.7923 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.1342 - accuracy: 0.6930\n",
            "Epoch 5: val_accuracy did not improve from 0.79231\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 2.1342 - accuracy: 0.6930 - val_loss: 2.6305 - val_accuracy: 0.6731 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.1651 - accuracy: 0.6925\n",
            "Epoch 6: val_accuracy improved from 0.79231 to 0.81154, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 2.1651 - accuracy: 0.6925 - val_loss: 0.8691 - val_accuracy: 0.8115 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.0398 - accuracy: 0.7093\n",
            "Epoch 7: val_accuracy improved from 0.81154 to 0.81538, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 2.0398 - accuracy: 0.7093 - val_loss: 0.7185 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.6486 - accuracy: 0.7281\n",
            "Epoch 8: val_accuracy improved from 0.81538 to 0.83077, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 7s 89ms/step - loss: 1.6486 - accuracy: 0.7281 - val_loss: 0.5444 - val_accuracy: 0.8308 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.5750 - accuracy: 0.7196\n",
            "Epoch 9: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 1.5750 - accuracy: 0.7196 - val_loss: 0.7188 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.4423 - accuracy: 0.7226\n",
            "Epoch 10: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 1.4423 - accuracy: 0.7226 - val_loss: 1.3084 - val_accuracy: 0.6923 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.1886 - accuracy: 0.7479\n",
            "Epoch 11: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 1.1886 - accuracy: 0.7479 - val_loss: 0.7000 - val_accuracy: 0.7885 - lr: 4.0000e-04\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.1234 - accuracy: 0.7547\n",
            "Epoch 12: val_accuracy improved from 0.83077 to 0.85385, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 1.1234 - accuracy: 0.7547 - val_loss: 0.4603 - val_accuracy: 0.8538 - lr: 4.0000e-04\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0908 - accuracy: 0.7513\n",
            "Epoch 13: val_accuracy did not improve from 0.85385\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 1.0908 - accuracy: 0.7513 - val_loss: 0.3671 - val_accuracy: 0.8538 - lr: 4.0000e-04\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0271 - accuracy: 0.7581\n",
            "Epoch 14: val_accuracy did not improve from 0.85385\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 1.0271 - accuracy: 0.7581 - val_loss: 0.6254 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8214 - accuracy: 0.7834\n",
            "Epoch 15: val_accuracy did not improve from 0.85385\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.8214 - accuracy: 0.7834 - val_loss: 0.7337 - val_accuracy: 0.8115 - lr: 1.6000e-04\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8881 - accuracy: 0.7684\n",
            "Epoch 16: val_accuracy did not improve from 0.85385\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.8881 - accuracy: 0.7684 - val_loss: 0.3866 - val_accuracy: 0.8385 - lr: 1.6000e-04\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.7796\n",
            "Epoch 17: val_accuracy improved from 0.85385 to 0.86923, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.8372 - accuracy: 0.7796 - val_loss: 0.3420 - val_accuracy: 0.8692 - lr: 6.4000e-05\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7896 - accuracy: 0.7903\n",
            "Epoch 18: val_accuracy did not improve from 0.86923\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.7896 - accuracy: 0.7903 - val_loss: 0.3678 - val_accuracy: 0.8538 - lr: 6.4000e-05\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7672 - accuracy: 0.7907\n",
            "Epoch 19: val_accuracy did not improve from 0.86923\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.7672 - accuracy: 0.7907 - val_loss: 0.3184 - val_accuracy: 0.8692 - lr: 6.4000e-05\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7944 - accuracy: 0.7766\n",
            "Epoch 20: val_accuracy improved from 0.86923 to 0.87308, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 0.7944 - accuracy: 0.7766 - val_loss: 0.3203 - val_accuracy: 0.8731 - lr: 2.5600e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd68e49f8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in resnet50.layers:\n",
        "    layer.trainable = False\n",
        "model_resnet50 = resnet50.output\n",
        "model_resnet50 = tf.keras.layers.GlobalAveragePooling2D()(model_resnet50)\n",
        "model_resnet50 = tf.keras.layers.Dropout(rate=0.5)(model_resnet50)\n",
        "model_resnet50 = tf.keras.layers.Dense(2,activation='softmax')(model_resnet50)\n",
        "model_resnet50 = tf.keras.models.Model(inputs=resnet50.input, outputs = model_resnet50)\n",
        "model_resnet50.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"resnet50.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_resnet50.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeMOuAdkqN55",
        "outputId": "90038d10-fb9b-4fe1-a35e-7d8fe7142204"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8851 - accuracy: 0.5828\n",
            "Epoch 1: val_accuracy improved from -inf to 0.67308, saving model to resnet50.h5\n",
            "73/73 [==============================] - 14s 137ms/step - loss: 0.8851 - accuracy: 0.5828 - val_loss: 0.5593 - val_accuracy: 0.6731 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.6801\n",
            "Epoch 2: val_accuracy improved from 0.67308 to 0.80769, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 109ms/step - loss: 0.6249 - accuracy: 0.6801 - val_loss: 0.4318 - val_accuracy: 0.8077 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5410 - accuracy: 0.7324\n",
            "Epoch 3: val_accuracy improved from 0.80769 to 0.84231, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 110ms/step - loss: 0.5410 - accuracy: 0.7324 - val_loss: 0.3923 - val_accuracy: 0.8423 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4779 - accuracy: 0.7714\n",
            "Epoch 4: val_accuracy improved from 0.84231 to 0.86154, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 117ms/step - loss: 0.4779 - accuracy: 0.7714 - val_loss: 0.3744 - val_accuracy: 0.8615 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.7783\n",
            "Epoch 5: val_accuracy improved from 0.86154 to 0.87692, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 111ms/step - loss: 0.4601 - accuracy: 0.7783 - val_loss: 0.3414 - val_accuracy: 0.8769 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.7993\n",
            "Epoch 6: val_accuracy improved from 0.87692 to 0.88846, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 118ms/step - loss: 0.4367 - accuracy: 0.7993 - val_loss: 0.3246 - val_accuracy: 0.8885 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.8130\n",
            "Epoch 7: val_accuracy improved from 0.88846 to 0.89615, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 118ms/step - loss: 0.4036 - accuracy: 0.8130 - val_loss: 0.3202 - val_accuracy: 0.8962 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4146 - accuracy: 0.8139\n",
            "Epoch 8: val_accuracy did not improve from 0.89615\n",
            "73/73 [==============================] - 8s 103ms/step - loss: 0.4146 - accuracy: 0.8139 - val_loss: 0.3485 - val_accuracy: 0.8500 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8199\n",
            "Epoch 9: val_accuracy improved from 0.89615 to 0.90000, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 110ms/step - loss: 0.3903 - accuracy: 0.8199 - val_loss: 0.3061 - val_accuracy: 0.9000 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3769 - accuracy: 0.8246\n",
            "Epoch 10: val_accuracy did not improve from 0.90000\n",
            "73/73 [==============================] - 8s 111ms/step - loss: 0.3769 - accuracy: 0.8246 - val_loss: 0.3261 - val_accuracy: 0.8962 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8195\n",
            "Epoch 11: val_accuracy improved from 0.90000 to 0.90769, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 110ms/step - loss: 0.3779 - accuracy: 0.8195 - val_loss: 0.2878 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.8319\n",
            "Epoch 12: val_accuracy did not improve from 0.90769\n",
            "73/73 [==============================] - 8s 104ms/step - loss: 0.3785 - accuracy: 0.8319 - val_loss: 0.2944 - val_accuracy: 0.8808 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3529 - accuracy: 0.8473\n",
            "Epoch 13: val_accuracy did not improve from 0.90769\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 8s 111ms/step - loss: 0.3529 - accuracy: 0.8473 - val_loss: 0.2839 - val_accuracy: 0.9000 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.8572\n",
            "Epoch 14: val_accuracy did not improve from 0.90769\n",
            "73/73 [==============================] - 8s 103ms/step - loss: 0.3464 - accuracy: 0.8572 - val_loss: 0.2792 - val_accuracy: 0.9000 - lr: 4.0000e-04\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.8426\n",
            "Epoch 15: val_accuracy improved from 0.90769 to 0.91538, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 117ms/step - loss: 0.3505 - accuracy: 0.8426 - val_loss: 0.2657 - val_accuracy: 0.9154 - lr: 4.0000e-04\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3323 - accuracy: 0.8559\n",
            "Epoch 16: val_accuracy did not improve from 0.91538\n",
            "73/73 [==============================] - 8s 103ms/step - loss: 0.3323 - accuracy: 0.8559 - val_loss: 0.2612 - val_accuracy: 0.9154 - lr: 4.0000e-04\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.8461\n",
            "Epoch 17: val_accuracy improved from 0.91538 to 0.91923, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 118ms/step - loss: 0.3462 - accuracy: 0.8461 - val_loss: 0.2629 - val_accuracy: 0.9192 - lr: 4.0000e-04\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8461\n",
            "Epoch 18: val_accuracy did not improve from 0.91923\n",
            "73/73 [==============================] - 8s 104ms/step - loss: 0.3434 - accuracy: 0.8461 - val_loss: 0.2704 - val_accuracy: 0.9000 - lr: 4.0000e-04\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.8533\n",
            "Epoch 19: val_accuracy did not improve from 0.91923\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 8s 104ms/step - loss: 0.3389 - accuracy: 0.8533 - val_loss: 0.2603 - val_accuracy: 0.9192 - lr: 4.0000e-04\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.8563\n",
            "Epoch 20: val_accuracy improved from 0.91923 to 0.92308, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 118ms/step - loss: 0.3333 - accuracy: 0.8563 - val_loss: 0.2622 - val_accuracy: 0.9231 - lr: 1.6000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd5d64c5b50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"ourmodel.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsVTnwPyuh02",
        "outputId": "1458bfad-e11d-4885-e34c-fa1a9c3476f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 30.8165 - accuracy: 0.7714\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89231, saving model to ourmodel.h5\n",
            "73/73 [==============================] - 7s 71ms/step - loss: 30.8165 - accuracy: 0.7714 - val_loss: 0.2406 - val_accuracy: 0.8923 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9443\n",
            "Epoch 2: val_accuracy improved from 0.89231 to 0.98077, saving model to ourmodel.h5\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.1432 - accuracy: 0.9443 - val_loss: 0.0782 - val_accuracy: 0.9808 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9727\n",
            "Epoch 3: val_accuracy improved from 0.98077 to 0.99615, saving model to ourmodel.h5\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.0758 - accuracy: 0.9721 - val_loss: 0.0353 - val_accuracy: 0.9962 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0452 - accuracy: 0.9848\n",
            "Epoch 4: val_accuracy did not improve from 0.99615\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0451 - accuracy: 0.9850 - val_loss: 0.0479 - val_accuracy: 0.9769 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9926\n",
            "Epoch 5: val_accuracy did not improve from 0.99615\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.0151 - val_accuracy: 0.9962 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9979\n",
            "Epoch 6: val_accuracy improved from 0.99615 to 1.00000, saving model to ourmodel.h5\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0067 - val_accuracy: 1.0000 - lr: 4.0000e-04\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9962 - lr: 4.0000e-04\n",
            "Epoch 8/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9983\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.0108 - val_accuracy: 0.9962 - lr: 4.0000e-04\n",
            "Epoch 9/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000 - lr: 1.6000e-04\n",
            "Epoch 10/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - lr: 1.6000e-04\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 6.4000e-05\n",
            "Epoch 12/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 6.4000e-05\n",
            "Epoch 13/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9996\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 2.5600e-05\n",
            "Epoch 14/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 2.5600e-05\n",
            "Epoch 15/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.0240e-05\n",
            "Epoch 16/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.0240e-05\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 4.0960e-06\n",
            "Epoch 18/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 9.8671e-04 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 9.7514e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 4.0960e-06\n",
            "Epoch 19/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.6384e-06\n",
            "Epoch 20/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 9.1687e-04 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.553600542247295e-07.\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 9.0920e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.6384e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd5d6171f50>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict probabilities\n",
        "pred_prob1 = model_vgg16.predict(X_test)\n",
        "pred_prob2 = model_vgg19.predict(X_test)\n",
        "pred_prob3 = model_efficientnet.predict(X_test)\n",
        "pred_prob4 = model_inceptionv3.predict(X_test)\n",
        "pred_prob5 = model_resnet50.predict(X_test)\n",
        "pred_prob6 = model.predict(X_test)"
      ],
      "metadata": {
        "id": "JSB7eoLbHss9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.argmax(y_test,axis=1)"
      ],
      "metadata": {
        "id": "za-Vz4zK3Pbz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# roc curve for models\n",
        "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\n",
        "fpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2[:,1], pos_label=1)\n",
        "fpr3, tpr3, thresh3 = roc_curve(y_test, pred_prob3[:,1], pos_label=1)\n",
        "fpr4, tpr4, thresh4 = roc_curve(y_test, pred_prob4[:,1], pos_label=1)\n",
        "fpr5, tpr5, thresh5 = roc_curve(y_test, pred_prob5[:,1], pos_label=1)\n",
        "fpr6, tpr6, thresh6 = roc_curve(y_test, pred_prob6[:,1], pos_label=1)\n",
        "\n",
        "# roc curve for tpr = fpr \n",
        "random_probs = [0 for i in range(len(y_test))]\n",
        "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
      ],
      "metadata": {
        "id": "pl_tqxt1M1y6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# auc scores\n",
        "auc_score_vgg16 = roc_auc_score(y_test, pred_prob1[:,1])\n",
        "auc_score_vgg19 = roc_auc_score(y_test, pred_prob2[:,1])\n",
        "auc_score_efficientnet = roc_auc_score(y_test, pred_prob3[:,1])\n",
        "auc_score_inceptionv3 = roc_auc_score(y_test, pred_prob4[:,1])\n",
        "auc_score_resnet50 = roc_auc_score(y_test, pred_prob5[:,1])\n",
        "auc_score_model = roc_auc_score(y_test, pred_prob6[:,1])\n",
        "\n",
        "print(auc_score_vgg16, auc_score_vgg19, auc_score_efficientnet, auc_score_inceptionv3, auc_score_resnet50, auc_score_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENolX_5GRrTE",
        "outputId": "57804270-2213-4ebc-e96d-5fa970238997"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9230399461616112 0.930606162572706 0.9424890640772965 0.9330961880498007 0.9704754122001634 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# plot roc curves\n",
        "plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='VGG-16')\n",
        "plt.plot(fpr2, tpr2, linestyle='--',color='green', label='VGG-19')\n",
        "plt.plot(fpr3, tpr3, linestyle='--',color='yellow', label='EfficientNet')\n",
        "plt.plot(fpr4, tpr4, linestyle='--',color='violet', label='InceptionV3')\n",
        "plt.plot(fpr5, tpr5, linestyle='--',color='purple', label='ResNet50')\n",
        "plt.plot(fpr6, tpr6, linestyle='--',color='red', label='OurModel')\n",
        "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
        "# title\n",
        "plt.title('ROC curve')\n",
        "# x label\n",
        "plt.xlabel('False Positive Rate')\n",
        "# y label\n",
        "plt.ylabel('True Positive rate')\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('ROC',dpi=300)\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "hWfi5wqBEgNG",
        "outputId": "d38767d2-6182-4e18-ad7f-f10d4cdb57f1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WvpmdasUGxJk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}