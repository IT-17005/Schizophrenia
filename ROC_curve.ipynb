{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ROC_curve.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLQKaV5QZUVzra49A3qJeE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IT-17005/Schizophrenia/blob/main/ROC_curve.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PZNMgps9_Iyq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import ipywidgets as widgets\n",
        "import io\n",
        "from PIL import Image\n",
        "from IPython.display import display,clear_output\n",
        "from warnings import filterwarnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SirXNPr3_f8N",
        "outputId": "497ff5f4-5930-4ac4-bbe2-c16f9afc3d2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['non-scz','scz']"
      ],
      "metadata": {
        "id": "l1kLty_E_21x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "image_size = 224\n",
        "for i in labels:\n",
        "    folderPath = os.path.join('/content/gdrive/MyDrive/SchiFinalDataset','train',i)\n",
        "    for j in tqdm(os.listdir(folderPath)):\n",
        "        img = cv2.imread(os.path.join(folderPath,j))\n",
        "        img = cv2.resize(img,(image_size, image_size))\n",
        "        X_train.append(img)\n",
        "        y_train.append(i)\n",
        "        \n",
        "for i in labels:\n",
        "    folderPath = os.path.join('/content/gdrive/MyDrive/SchiFinalDataset','val',i)\n",
        "    for j in tqdm(os.listdir(folderPath)):\n",
        "        img = cv2.imread(os.path.join(folderPath,j))\n",
        "        img = cv2.resize(img,(image_size,image_size))\n",
        "        X_train.append(img)\n",
        "        y_train.append(i)\n",
        "        \n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzqZWzOI_vyQ",
        "outputId": "38a81a83-4c60-455e-cf93-439816e7e518"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1400/1400 [00:06<00:00, 233.13it/s]\n",
            "100%|██████████| 1120/1120 [00:27<00:00, 40.85it/s] \n",
            "100%|██████████| 400/400 [00:07<00:00, 55.81it/s] \n",
            "100%|██████████| 320/320 [00:06<00:00, 52.40it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = shuffle(X_train,y_train, random_state=101)"
      ],
      "metadata": {
        "id": "EIeso4YLBAtE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFW9DoAcBEHJ",
        "outputId": "e67e5e96-a9f0-4a95-e689-a7fc25eb9db2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3240, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.2,random_state=101)"
      ],
      "metadata": {
        "id": "WGNySMb_BKDC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_new = []\n",
        "for i in y_train:\n",
        "    y_train_new.append(labels.index(i))\n",
        "y_train = y_train_new\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "\n",
        "\n",
        "y_test_new = []\n",
        "for i in y_test:\n",
        "    y_test_new.append(labels.index(i))\n",
        "y_test = y_test_new\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "-V8cqIUIBMHm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "vgg16 = VGG16(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "vgg19 = VGG19(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "efficientnet = tf.keras.applications.EfficientNetB0(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "inceptionv3 = tf.keras.applications.InceptionV3(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "resnet50 = ResNet50(input_shape=(image_size,image_size,3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYo65QklCKUc",
        "outputId": "af540f25-ae99-49f5-96e8-aa23ff509e75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 0s 0us/step\n",
            "80150528/80134624 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n",
            "87924736/87910968 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input,Dense\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size,image_size,3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "R61IYZ5Vr-BG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "model_vgg16 = vgg16.output\n",
        "model_vgg16 = tf.keras.layers.GlobalAveragePooling2D()(model_vgg16)\n",
        "model_vgg16 = tf.keras.layers.Dropout(rate=0.5)(model_vgg16)\n",
        "model_vgg16 = tf.keras.layers.Dense(2,activation='softmax')(model_vgg16)\n",
        "model_vgg16 = tf.keras.models.Model(inputs=vgg16.input, outputs = model_vgg16)\n",
        "model_vgg16.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"vgg16.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_vgg16.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu-DtmCQFgen",
        "outputId": "b37a6930-8834-4391-916d-3f9fb2b2dc77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.8116 - accuracy: 0.5330\n",
            "Epoch 1: val_accuracy improved from -inf to 0.63077, saving model to vgg16.h5\n",
            "73/73 [==============================] - 28s 202ms/step - loss: 2.8116 - accuracy: 0.5330 - val_loss: 0.8285 - val_accuracy: 0.6308 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.6333 - accuracy: 0.5840\n",
            "Epoch 2: val_accuracy improved from 0.63077 to 0.73462, saving model to vgg16.h5\n",
            "73/73 [==============================] - 12s 158ms/step - loss: 1.6333 - accuracy: 0.5840 - val_loss: 0.6144 - val_accuracy: 0.7346 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0593 - accuracy: 0.6321\n",
            "Epoch 3: val_accuracy did not improve from 0.73462\n",
            "73/73 [==============================] - 12s 159ms/step - loss: 1.0593 - accuracy: 0.6321 - val_loss: 0.5782 - val_accuracy: 0.7115 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8030 - accuracy: 0.6685\n",
            "Epoch 4: val_accuracy improved from 0.73462 to 0.78077, saving model to vgg16.h5\n",
            "73/73 [==============================] - 12s 162ms/step - loss: 0.8030 - accuracy: 0.6685 - val_loss: 0.4630 - val_accuracy: 0.7808 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6536 - accuracy: 0.7097\n",
            "Epoch 5: val_accuracy improved from 0.78077 to 0.81923, saving model to vgg16.h5\n",
            "73/73 [==============================] - 12s 161ms/step - loss: 0.6536 - accuracy: 0.7097 - val_loss: 0.4226 - val_accuracy: 0.8192 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6294 - accuracy: 0.7153\n",
            "Epoch 6: val_accuracy did not improve from 0.81923\n",
            "73/73 [==============================] - 12s 160ms/step - loss: 0.6294 - accuracy: 0.7153 - val_loss: 0.4389 - val_accuracy: 0.8115 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.7496\n",
            "Epoch 7: val_accuracy did not improve from 0.81923\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 12s 164ms/step - loss: 0.5427 - accuracy: 0.7496 - val_loss: 0.4070 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.7646\n",
            "Epoch 8: val_accuracy improved from 0.81923 to 0.83846, saving model to vgg16.h5\n",
            "73/73 [==============================] - 12s 166ms/step - loss: 0.5104 - accuracy: 0.7646 - val_loss: 0.3923 - val_accuracy: 0.8385 - lr: 4.0000e-04\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5049 - accuracy: 0.7526\n",
            "Epoch 9: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 166ms/step - loss: 0.5049 - accuracy: 0.7526 - val_loss: 0.4269 - val_accuracy: 0.8269 - lr: 4.0000e-04\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.7577\n",
            "Epoch 10: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 12s 162ms/step - loss: 0.5050 - accuracy: 0.7577 - val_loss: 0.3951 - val_accuracy: 0.8231 - lr: 4.0000e-04\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4781 - accuracy: 0.7766\n",
            "Epoch 11: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 164ms/step - loss: 0.4781 - accuracy: 0.7766 - val_loss: 0.3973 - val_accuracy: 0.8231 - lr: 1.6000e-04\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.7650\n",
            "Epoch 12: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 12s 165ms/step - loss: 0.4844 - accuracy: 0.7650 - val_loss: 0.4117 - val_accuracy: 0.8269 - lr: 1.6000e-04\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4865 - accuracy: 0.7693\n",
            "Epoch 13: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 165ms/step - loss: 0.4865 - accuracy: 0.7693 - val_loss: 0.4012 - val_accuracy: 0.8192 - lr: 6.4000e-05\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.7684\n",
            "Epoch 14: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
            "73/73 [==============================] - 12s 166ms/step - loss: 0.4849 - accuracy: 0.7684 - val_loss: 0.4004 - val_accuracy: 0.8192 - lr: 6.4000e-05\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.7697\n",
            "Epoch 15: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 165ms/step - loss: 0.4742 - accuracy: 0.7697 - val_loss: 0.3977 - val_accuracy: 0.8154 - lr: 2.5600e-05\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.7736\n",
            "Epoch 16: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
            "73/73 [==============================] - 12s 165ms/step - loss: 0.4749 - accuracy: 0.7736 - val_loss: 0.3979 - val_accuracy: 0.8269 - lr: 2.5600e-05\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4699 - accuracy: 0.7710\n",
            "Epoch 17: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 167ms/step - loss: 0.4699 - accuracy: 0.7710 - val_loss: 0.3980 - val_accuracy: 0.8231 - lr: 1.0240e-05\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.7633\n",
            "Epoch 18: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
            "73/73 [==============================] - 12s 166ms/step - loss: 0.4860 - accuracy: 0.7633 - val_loss: 0.3978 - val_accuracy: 0.8231 - lr: 1.0240e-05\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.7830\n",
            "Epoch 19: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 12s 167ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.3977 - val_accuracy: 0.8192 - lr: 4.0960e-06\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.7792\n",
            "Epoch 20: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
            "73/73 [==============================] - 12s 168ms/step - loss: 0.4579 - accuracy: 0.7792 - val_loss: 0.3979 - val_accuracy: 0.8192 - lr: 4.0960e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6d2ec89d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False\n",
        "model_vgg19 = vgg19.output\n",
        "model_vgg19 = tf.keras.layers.GlobalAveragePooling2D()(model_vgg19)\n",
        "model_vgg19 = tf.keras.layers.Dropout(rate=0.5)(model_vgg19)\n",
        "model_vgg19 = tf.keras.layers.Dense(2,activation='softmax')(model_vgg19)\n",
        "model_vgg19 = tf.keras.models.Model(inputs=vgg19.input, outputs = model_vgg19)\n",
        "model_vgg19.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"vgg19.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_vgg19.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSg9aUqVG28y",
        "outputId": "6894bd39-d414-4168-956c-a7f664846463"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.4675 - accuracy: 0.5081\n",
            "Epoch 1: val_accuracy improved from -inf to 0.61154, saving model to vgg19.h5\n",
            "73/73 [==============================] - 15s 200ms/step - loss: 2.4675 - accuracy: 0.5081 - val_loss: 0.8933 - val_accuracy: 0.6115 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.4981 - accuracy: 0.5733\n",
            "Epoch 2: val_accuracy improved from 0.61154 to 0.63462, saving model to vgg19.h5\n",
            "73/73 [==============================] - 14s 198ms/step - loss: 1.4981 - accuracy: 0.5733 - val_loss: 0.6492 - val_accuracy: 0.6346 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9450 - accuracy: 0.6372\n",
            "Epoch 3: val_accuracy improved from 0.63462 to 0.70000, saving model to vgg19.h5\n",
            "73/73 [==============================] - 16s 214ms/step - loss: 0.9450 - accuracy: 0.6372 - val_loss: 0.5498 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7835 - accuracy: 0.6432\n",
            "Epoch 4: val_accuracy improved from 0.70000 to 0.71154, saving model to vgg19.h5\n",
            "73/73 [==============================] - 14s 199ms/step - loss: 0.7835 - accuracy: 0.6432 - val_loss: 0.5179 - val_accuracy: 0.7115 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6740 - accuracy: 0.6938\n",
            "Epoch 5: val_accuracy improved from 0.71154 to 0.75769, saving model to vgg19.h5\n",
            "73/73 [==============================] - 15s 199ms/step - loss: 0.6740 - accuracy: 0.6938 - val_loss: 0.4812 - val_accuracy: 0.7577 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6083 - accuracy: 0.7071\n",
            "Epoch 6: val_accuracy did not improve from 0.75769\n",
            "73/73 [==============================] - 15s 213ms/step - loss: 0.6083 - accuracy: 0.7071 - val_loss: 0.5644 - val_accuracy: 0.6769 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5957 - accuracy: 0.7075\n",
            "Epoch 7: val_accuracy improved from 0.75769 to 0.77308, saving model to vgg19.h5\n",
            "73/73 [==============================] - 15s 200ms/step - loss: 0.5957 - accuracy: 0.7075 - val_loss: 0.4519 - val_accuracy: 0.7731 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5464 - accuracy: 0.7354\n",
            "Epoch 8: val_accuracy did not improve from 0.77308\n",
            "73/73 [==============================] - 16s 213ms/step - loss: 0.5464 - accuracy: 0.7354 - val_loss: 0.4982 - val_accuracy: 0.7615 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5344 - accuracy: 0.7213\n",
            "Epoch 9: val_accuracy improved from 0.77308 to 0.81154, saving model to vgg19.h5\n",
            "73/73 [==============================] - 16s 216ms/step - loss: 0.5344 - accuracy: 0.7213 - val_loss: 0.4398 - val_accuracy: 0.8115 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.7337\n",
            "Epoch 10: val_accuracy improved from 0.81154 to 0.81538, saving model to vgg19.h5\n",
            "73/73 [==============================] - 16s 216ms/step - loss: 0.5501 - accuracy: 0.7337 - val_loss: 0.4494 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.7311\n",
            "Epoch 11: val_accuracy did not improve from 0.81538\n",
            "73/73 [==============================] - 14s 198ms/step - loss: 0.5620 - accuracy: 0.7311 - val_loss: 0.4554 - val_accuracy: 0.7731 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.7393\n",
            "Epoch 12: val_accuracy did not improve from 0.81538\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 16s 214ms/step - loss: 0.5298 - accuracy: 0.7393 - val_loss: 0.4791 - val_accuracy: 0.7769 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.7642\n",
            "Epoch 13: val_accuracy improved from 0.81538 to 0.83077, saving model to vgg19.h5\n",
            "73/73 [==============================] - 15s 202ms/step - loss: 0.5024 - accuracy: 0.7642 - val_loss: 0.4216 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.7543\n",
            "Epoch 14: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 16s 216ms/step - loss: 0.4958 - accuracy: 0.7543 - val_loss: 0.4209 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.7500\n",
            "Epoch 15: val_accuracy improved from 0.83077 to 0.83846, saving model to vgg19.h5\n",
            "73/73 [==============================] - 16s 221ms/step - loss: 0.5084 - accuracy: 0.7500 - val_loss: 0.4300 - val_accuracy: 0.8385 - lr: 4.0000e-04\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.7599\n",
            "Epoch 16: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 15s 204ms/step - loss: 0.4915 - accuracy: 0.7599 - val_loss: 0.4322 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.7496\n",
            "Epoch 17: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 15s 204ms/step - loss: 0.5032 - accuracy: 0.7496 - val_loss: 0.4228 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4937 - accuracy: 0.7629\n",
            "Epoch 18: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 16s 218ms/step - loss: 0.4937 - accuracy: 0.7629 - val_loss: 0.4223 - val_accuracy: 0.8231 - lr: 1.6000e-04\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5008 - accuracy: 0.7667\n",
            "Epoch 19: val_accuracy did not improve from 0.83846\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 16s 218ms/step - loss: 0.5008 - accuracy: 0.7667 - val_loss: 0.4197 - val_accuracy: 0.8308 - lr: 1.6000e-04\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4887 - accuracy: 0.7611\n",
            "Epoch 20: val_accuracy did not improve from 0.83846\n",
            "73/73 [==============================] - 16s 218ms/step - loss: 0.4887 - accuracy: 0.7611 - val_loss: 0.4217 - val_accuracy: 0.8385 - lr: 6.4000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6d2e0dd10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in efficientnet.layers:\n",
        "    layer.trainable = False\n",
        "model_efficientnet = efficientnet.output\n",
        "model_efficientnet = tf.keras.layers.GlobalAveragePooling2D()(model_efficientnet)\n",
        "model_efficientnet = tf.keras.layers.Dropout(rate=0.5)(model_efficientnet)\n",
        "model_efficientnet = tf.keras.layers.Dense(2,activation='softmax')(model_efficientnet)\n",
        "model_efficientnet = tf.keras.models.Model(inputs=efficientnet.input, outputs = model_efficientnet)\n",
        "model_efficientnet.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"efficientnet.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_efficientnet.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psLJGI27q0uH",
        "outputId": "5c59a7b3-8bd6-4a7b-f3dc-4803c3026aa3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7223 - accuracy: 0.5617\n",
            "Epoch 1: val_accuracy improved from -inf to 0.71923, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 14s 109ms/step - loss: 0.7223 - accuracy: 0.5617 - val_loss: 0.5913 - val_accuracy: 0.7192 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5891 - accuracy: 0.6913\n",
            "Epoch 2: val_accuracy did not improve from 0.71923\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.5891 - accuracy: 0.6913 - val_loss: 0.5593 - val_accuracy: 0.6731 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.7230\n",
            "Epoch 3: val_accuracy improved from 0.71923 to 0.74231, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.5486 - accuracy: 0.7230 - val_loss: 0.5108 - val_accuracy: 0.7423 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.7350\n",
            "Epoch 4: val_accuracy improved from 0.74231 to 0.78846, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.5230 - accuracy: 0.7350 - val_loss: 0.4734 - val_accuracy: 0.7885 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5135 - accuracy: 0.7363\n",
            "Epoch 5: val_accuracy improved from 0.78846 to 0.82308, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.5135 - accuracy: 0.7363 - val_loss: 0.4584 - val_accuracy: 0.8231 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.7517\n",
            "Epoch 6: val_accuracy did not improve from 0.82308\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.4974 - accuracy: 0.7517 - val_loss: 0.4580 - val_accuracy: 0.7962 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.7650\n",
            "Epoch 7: val_accuracy did not improve from 0.82308\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.4799 - accuracy: 0.7650 - val_loss: 0.4289 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4600 - accuracy: 0.7749\n",
            "Epoch 8: val_accuracy improved from 0.82308 to 0.83077, saving model to efficientnet.h5\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.4600 - accuracy: 0.7749 - val_loss: 0.4248 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.7933\n",
            "Epoch 9: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4526 - accuracy: 0.7933 - val_loss: 0.4249 - val_accuracy: 0.8231 - lr: 4.0000e-04\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.7882\n",
            "Epoch 10: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4189 - val_accuracy: 0.8269 - lr: 4.0000e-04\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4610 - accuracy: 0.7882\n",
            "Epoch 11: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4610 - accuracy: 0.7882 - val_loss: 0.4160 - val_accuracy: 0.8308 - lr: 1.6000e-04\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.7946\n",
            "Epoch 12: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4503 - accuracy: 0.7946 - val_loss: 0.4181 - val_accuracy: 0.8192 - lr: 1.6000e-04\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.7834\n",
            "Epoch 13: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4503 - accuracy: 0.7834 - val_loss: 0.4190 - val_accuracy: 0.8115 - lr: 6.4000e-05\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.7907\n",
            "Epoch 14: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.4526 - accuracy: 0.7907 - val_loss: 0.4175 - val_accuracy: 0.8231 - lr: 6.4000e-05\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.7955\n",
            "Epoch 15: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.4443 - accuracy: 0.7955 - val_loss: 0.4166 - val_accuracy: 0.8192 - lr: 2.5600e-05\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.7937\n",
            "Epoch 16: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4468 - accuracy: 0.7937 - val_loss: 0.4153 - val_accuracy: 0.8154 - lr: 2.5600e-05\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.7946\n",
            "Epoch 17: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.4446 - accuracy: 0.7946 - val_loss: 0.4152 - val_accuracy: 0.8154 - lr: 1.0240e-05\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.8032\n",
            "Epoch 18: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.4292 - accuracy: 0.8032 - val_loss: 0.4148 - val_accuracy: 0.8154 - lr: 1.0240e-05\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.7916\n",
            "Epoch 19: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4505 - accuracy: 0.7916 - val_loss: 0.4148 - val_accuracy: 0.8154 - lr: 4.0960e-06\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4445 - accuracy: 0.7899\n",
            "Epoch 20: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.4445 - accuracy: 0.7899 - val_loss: 0.4149 - val_accuracy: 0.8154 - lr: 4.0960e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6d2b68950>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in inceptionv3.layers:\n",
        "    layer.trainable = False\n",
        "model_inceptionv3 = inceptionv3.output\n",
        "model_inceptionv3 = tf.keras.layers.GlobalAveragePooling2D()(model_inceptionv3)\n",
        "model_inceptionv3 = tf.keras.layers.Dropout(rate=0.5)(model_inceptionv3)\n",
        "model_inceptionv3 = tf.keras.layers.Dense(2,activation='softmax')(model_inceptionv3)\n",
        "model_inceptionv3 = tf.keras.models.Model(inputs=inceptionv3.input, outputs = model_inceptionv3)\n",
        "model_inceptionv3.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"inceptionv3.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_inceptionv3.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o408EPZrs5gm",
        "outputId": "36d2d132-f554-41ca-e7be-d75980afb4e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 10.1004 - accuracy: 0.5180\n",
            "Epoch 1: val_accuracy improved from -inf to 0.63077, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 14s 127ms/step - loss: 10.1004 - accuracy: 0.5180 - val_loss: 2.0707 - val_accuracy: 0.6308 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 4.6128 - accuracy: 0.6141\n",
            "Epoch 2: val_accuracy improved from 0.63077 to 0.75385, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 4.6128 - accuracy: 0.6141 - val_loss: 1.5935 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 3.2126 - accuracy: 0.6621\n",
            "Epoch 3: val_accuracy improved from 0.75385 to 0.77692, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 3.2126 - accuracy: 0.6621 - val_loss: 1.1248 - val_accuracy: 0.7769 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.1227 - accuracy: 0.7028\n",
            "Epoch 4: val_accuracy improved from 0.77692 to 0.79231, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 2.1227 - accuracy: 0.7028 - val_loss: 0.9429 - val_accuracy: 0.7923 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.1342 - accuracy: 0.6930\n",
            "Epoch 5: val_accuracy did not improve from 0.79231\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 2.1342 - accuracy: 0.6930 - val_loss: 2.6305 - val_accuracy: 0.6731 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.1651 - accuracy: 0.6925\n",
            "Epoch 6: val_accuracy improved from 0.79231 to 0.81154, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 2.1651 - accuracy: 0.6925 - val_loss: 0.8691 - val_accuracy: 0.8115 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 2.0398 - accuracy: 0.7093\n",
            "Epoch 7: val_accuracy improved from 0.81154 to 0.81538, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 2.0398 - accuracy: 0.7093 - val_loss: 0.7185 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.6486 - accuracy: 0.7281\n",
            "Epoch 8: val_accuracy improved from 0.81538 to 0.83077, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 7s 89ms/step - loss: 1.6486 - accuracy: 0.7281 - val_loss: 0.5444 - val_accuracy: 0.8308 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.5750 - accuracy: 0.7196\n",
            "Epoch 9: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 1.5750 - accuracy: 0.7196 - val_loss: 0.7188 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.4423 - accuracy: 0.7226\n",
            "Epoch 10: val_accuracy did not improve from 0.83077\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 1.4423 - accuracy: 0.7226 - val_loss: 1.3084 - val_accuracy: 0.6923 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.1886 - accuracy: 0.7479\n",
            "Epoch 11: val_accuracy did not improve from 0.83077\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 1.1886 - accuracy: 0.7479 - val_loss: 0.7000 - val_accuracy: 0.7885 - lr: 4.0000e-04\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.1234 - accuracy: 0.7547\n",
            "Epoch 12: val_accuracy improved from 0.83077 to 0.85385, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 1.1234 - accuracy: 0.7547 - val_loss: 0.4603 - val_accuracy: 0.8538 - lr: 4.0000e-04\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0908 - accuracy: 0.7513\n",
            "Epoch 13: val_accuracy did not improve from 0.85385\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 1.0908 - accuracy: 0.7513 - val_loss: 0.3671 - val_accuracy: 0.8538 - lr: 4.0000e-04\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0271 - accuracy: 0.7581\n",
            "Epoch 14: val_accuracy did not improve from 0.85385\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 1.0271 - accuracy: 0.7581 - val_loss: 0.6254 - val_accuracy: 0.8308 - lr: 4.0000e-04\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8214 - accuracy: 0.7834\n",
            "Epoch 15: val_accuracy did not improve from 0.85385\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.8214 - accuracy: 0.7834 - val_loss: 0.7337 - val_accuracy: 0.8115 - lr: 1.6000e-04\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8881 - accuracy: 0.7684\n",
            "Epoch 16: val_accuracy did not improve from 0.85385\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.8881 - accuracy: 0.7684 - val_loss: 0.3866 - val_accuracy: 0.8385 - lr: 1.6000e-04\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.7796\n",
            "Epoch 17: val_accuracy improved from 0.85385 to 0.86923, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.8372 - accuracy: 0.7796 - val_loss: 0.3420 - val_accuracy: 0.8692 - lr: 6.4000e-05\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7896 - accuracy: 0.7903\n",
            "Epoch 18: val_accuracy did not improve from 0.86923\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.7896 - accuracy: 0.7903 - val_loss: 0.3678 - val_accuracy: 0.8538 - lr: 6.4000e-05\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7672 - accuracy: 0.7907\n",
            "Epoch 19: val_accuracy did not improve from 0.86923\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.7672 - accuracy: 0.7907 - val_loss: 0.3184 - val_accuracy: 0.8692 - lr: 6.4000e-05\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7944 - accuracy: 0.7766\n",
            "Epoch 20: val_accuracy improved from 0.86923 to 0.87308, saving model to inceptionv3.h5\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 0.7944 - accuracy: 0.7766 - val_loss: 0.3203 - val_accuracy: 0.8731 - lr: 2.5600e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd68e49f8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in resnet50.layers:\n",
        "    layer.trainable = False\n",
        "model_resnet50 = resnet50.output\n",
        "model_resnet50 = tf.keras.layers.GlobalAveragePooling2D()(model_resnet50)\n",
        "model_resnet50 = tf.keras.layers.Dropout(rate=0.5)(model_resnet50)\n",
        "model_resnet50 = tf.keras.layers.Dense(2,activation='softmax')(model_resnet50)\n",
        "model_resnet50 = tf.keras.models.Model(inputs=resnet50.input, outputs = model_resnet50)\n",
        "model_resnet50.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"resnet50.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model_resnet50.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeMOuAdkqN55",
        "outputId": "90038d10-fb9b-4fe1-a35e-7d8fe7142204"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8851 - accuracy: 0.5828\n",
            "Epoch 1: val_accuracy improved from -inf to 0.67308, saving model to resnet50.h5\n",
            "73/73 [==============================] - 14s 137ms/step - loss: 0.8851 - accuracy: 0.5828 - val_loss: 0.5593 - val_accuracy: 0.6731 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.6801\n",
            "Epoch 2: val_accuracy improved from 0.67308 to 0.80769, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 109ms/step - loss: 0.6249 - accuracy: 0.6801 - val_loss: 0.4318 - val_accuracy: 0.8077 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5410 - accuracy: 0.7324\n",
            "Epoch 3: val_accuracy improved from 0.80769 to 0.84231, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 110ms/step - loss: 0.5410 - accuracy: 0.7324 - val_loss: 0.3923 - val_accuracy: 0.8423 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4779 - accuracy: 0.7714\n",
            "Epoch 4: val_accuracy improved from 0.84231 to 0.86154, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 117ms/step - loss: 0.4779 - accuracy: 0.7714 - val_loss: 0.3744 - val_accuracy: 0.8615 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.7783\n",
            "Epoch 5: val_accuracy improved from 0.86154 to 0.87692, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 111ms/step - loss: 0.4601 - accuracy: 0.7783 - val_loss: 0.3414 - val_accuracy: 0.8769 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.7993\n",
            "Epoch 6: val_accuracy improved from 0.87692 to 0.88846, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 118ms/step - loss: 0.4367 - accuracy: 0.7993 - val_loss: 0.3246 - val_accuracy: 0.8885 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.8130\n",
            "Epoch 7: val_accuracy improved from 0.88846 to 0.89615, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 118ms/step - loss: 0.4036 - accuracy: 0.8130 - val_loss: 0.3202 - val_accuracy: 0.8962 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4146 - accuracy: 0.8139\n",
            "Epoch 8: val_accuracy did not improve from 0.89615\n",
            "73/73 [==============================] - 8s 103ms/step - loss: 0.4146 - accuracy: 0.8139 - val_loss: 0.3485 - val_accuracy: 0.8500 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8199\n",
            "Epoch 9: val_accuracy improved from 0.89615 to 0.90000, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 110ms/step - loss: 0.3903 - accuracy: 0.8199 - val_loss: 0.3061 - val_accuracy: 0.9000 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3769 - accuracy: 0.8246\n",
            "Epoch 10: val_accuracy did not improve from 0.90000\n",
            "73/73 [==============================] - 8s 111ms/step - loss: 0.3769 - accuracy: 0.8246 - val_loss: 0.3261 - val_accuracy: 0.8962 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8195\n",
            "Epoch 11: val_accuracy improved from 0.90000 to 0.90769, saving model to resnet50.h5\n",
            "73/73 [==============================] - 8s 110ms/step - loss: 0.3779 - accuracy: 0.8195 - val_loss: 0.2878 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.8319\n",
            "Epoch 12: val_accuracy did not improve from 0.90769\n",
            "73/73 [==============================] - 8s 104ms/step - loss: 0.3785 - accuracy: 0.8319 - val_loss: 0.2944 - val_accuracy: 0.8808 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3529 - accuracy: 0.8473\n",
            "Epoch 13: val_accuracy did not improve from 0.90769\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 8s 111ms/step - loss: 0.3529 - accuracy: 0.8473 - val_loss: 0.2839 - val_accuracy: 0.9000 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.8572\n",
            "Epoch 14: val_accuracy did not improve from 0.90769\n",
            "73/73 [==============================] - 8s 103ms/step - loss: 0.3464 - accuracy: 0.8572 - val_loss: 0.2792 - val_accuracy: 0.9000 - lr: 4.0000e-04\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.8426\n",
            "Epoch 15: val_accuracy improved from 0.90769 to 0.91538, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 117ms/step - loss: 0.3505 - accuracy: 0.8426 - val_loss: 0.2657 - val_accuracy: 0.9154 - lr: 4.0000e-04\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3323 - accuracy: 0.8559\n",
            "Epoch 16: val_accuracy did not improve from 0.91538\n",
            "73/73 [==============================] - 8s 103ms/step - loss: 0.3323 - accuracy: 0.8559 - val_loss: 0.2612 - val_accuracy: 0.9154 - lr: 4.0000e-04\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.8461\n",
            "Epoch 17: val_accuracy improved from 0.91538 to 0.91923, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 118ms/step - loss: 0.3462 - accuracy: 0.8461 - val_loss: 0.2629 - val_accuracy: 0.9192 - lr: 4.0000e-04\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8461\n",
            "Epoch 18: val_accuracy did not improve from 0.91923\n",
            "73/73 [==============================] - 8s 104ms/step - loss: 0.3434 - accuracy: 0.8461 - val_loss: 0.2704 - val_accuracy: 0.9000 - lr: 4.0000e-04\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.8533\n",
            "Epoch 19: val_accuracy did not improve from 0.91923\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 8s 104ms/step - loss: 0.3389 - accuracy: 0.8533 - val_loss: 0.2603 - val_accuracy: 0.9192 - lr: 4.0000e-04\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.8563\n",
            "Epoch 20: val_accuracy improved from 0.91923 to 0.92308, saving model to resnet50.h5\n",
            "73/73 [==============================] - 9s 118ms/step - loss: 0.3333 - accuracy: 0.8563 - val_loss: 0.2622 - val_accuracy: 0.9231 - lr: 1.6000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd5d64c5b50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "checkpoint = ModelCheckpoint(\"ourmodel.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "model.fit(X_train,y_train,validation_split=0.1, epochs =20, verbose=1, batch_size=32,\n",
        "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsVTnwPyuh02",
        "outputId": "1458bfad-e11d-4885-e34c-fa1a9c3476f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 30.8165 - accuracy: 0.7714\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89231, saving model to ourmodel.h5\n",
            "73/73 [==============================] - 7s 71ms/step - loss: 30.8165 - accuracy: 0.7714 - val_loss: 0.2406 - val_accuracy: 0.8923 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9443\n",
            "Epoch 2: val_accuracy improved from 0.89231 to 0.98077, saving model to ourmodel.h5\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.1432 - accuracy: 0.9443 - val_loss: 0.0782 - val_accuracy: 0.9808 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9727\n",
            "Epoch 3: val_accuracy improved from 0.98077 to 0.99615, saving model to ourmodel.h5\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.0758 - accuracy: 0.9721 - val_loss: 0.0353 - val_accuracy: 0.9962 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0452 - accuracy: 0.9848\n",
            "Epoch 4: val_accuracy did not improve from 0.99615\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0451 - accuracy: 0.9850 - val_loss: 0.0479 - val_accuracy: 0.9769 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9926\n",
            "Epoch 5: val_accuracy did not improve from 0.99615\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.0151 - val_accuracy: 0.9962 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9979\n",
            "Epoch 6: val_accuracy improved from 0.99615 to 1.00000, saving model to ourmodel.h5\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0067 - val_accuracy: 1.0000 - lr: 4.0000e-04\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9962 - lr: 4.0000e-04\n",
            "Epoch 8/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9983\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.0108 - val_accuracy: 0.9962 - lr: 4.0000e-04\n",
            "Epoch 9/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000 - lr: 1.6000e-04\n",
            "Epoch 10/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - lr: 1.6000e-04\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 6.4000e-05\n",
            "Epoch 12/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 6.4000e-05\n",
            "Epoch 13/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9996\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 2.5600e-05\n",
            "Epoch 14/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 2.5600e-05\n",
            "Epoch 15/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.0240e-05\n",
            "Epoch 16/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.0240e-05\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 4.0960e-06\n",
            "Epoch 18/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 9.8671e-04 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 9.7514e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 4.0960e-06\n",
            "Epoch 19/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.6384e-06\n",
            "Epoch 20/20\n",
            "72/73 [============================>.] - ETA: 0s - loss: 9.1687e-04 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.553600542247295e-07.\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 9.0920e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.6384e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd5d6171f50>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict probabilities\n",
        "pred_prob1 = model_vgg16.predict(X_test)\n",
        "pred_prob2 = model_vgg19.predict(X_test)\n",
        "pred_prob3 = model_efficientnet.predict(X_test)\n",
        "pred_prob4 = model_inceptionv3.predict(X_test)\n",
        "pred_prob5 = model_resnet50.predict(X_test)\n",
        "pred_prob6 = model.predict(X_test)"
      ],
      "metadata": {
        "id": "JSB7eoLbHss9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.argmax(y_test,axis=1)"
      ],
      "metadata": {
        "id": "za-Vz4zK3Pbz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# roc curve for models\n",
        "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\n",
        "fpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2[:,1], pos_label=1)\n",
        "fpr3, tpr3, thresh3 = roc_curve(y_test, pred_prob3[:,1], pos_label=1)\n",
        "fpr4, tpr4, thresh4 = roc_curve(y_test, pred_prob4[:,1], pos_label=1)\n",
        "fpr5, tpr5, thresh5 = roc_curve(y_test, pred_prob5[:,1], pos_label=1)\n",
        "fpr6, tpr6, thresh6 = roc_curve(y_test, pred_prob6[:,1], pos_label=1)\n",
        "\n",
        "# roc curve for tpr = fpr \n",
        "random_probs = [0 for i in range(len(y_test))]\n",
        "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
      ],
      "metadata": {
        "id": "pl_tqxt1M1y6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# auc scores\n",
        "auc_score_vgg16 = roc_auc_score(y_test, pred_prob1[:,1])\n",
        "auc_score_vgg19 = roc_auc_score(y_test, pred_prob2[:,1])\n",
        "auc_score_efficientnet = roc_auc_score(y_test, pred_prob3[:,1])\n",
        "auc_score_inceptionv3 = roc_auc_score(y_test, pred_prob4[:,1])\n",
        "auc_score_resnet50 = roc_auc_score(y_test, pred_prob5[:,1])\n",
        "auc_score_model = roc_auc_score(y_test, pred_prob6[:,1])\n",
        "\n",
        "print(auc_score_vgg16, auc_score_vgg19, auc_score_efficientnet, auc_score_inceptionv3, auc_score_resnet50, auc_score_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENolX_5GRrTE",
        "outputId": "57804270-2213-4ebc-e96d-5fa970238997"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9230399461616112 0.930606162572706 0.9424890640772965 0.9330961880498007 0.9704754122001634 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# plot roc curves\n",
        "plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='VGG-16 (AUC = 0.923)')\n",
        "plt.plot(fpr2, tpr2, linestyle='--',color='green', label='VGG-19 (AUC = 0.930)')\n",
        "plt.plot(fpr3, tpr3, linestyle='--',color='yellow', label='EfficientNet (AUC = 0.942)')\n",
        "plt.plot(fpr4, tpr4, linestyle='--',color='violet', label='InceptionV3 (AUC = 0.933)')\n",
        "plt.plot(fpr5, tpr5, linestyle='--',color='purple', label='ResNet50 (AUC = 0.970)')\n",
        "plt.plot(fpr6, tpr6, linestyle='--',color='red', label='OurModel (AUC = 1.0)')\n",
        "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
        "# title\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=14)\n",
        "plt.legend(prop={'size':14}, loc='lower right')\n",
        "# x label\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel('False Positive Rate', fontsize=14)\n",
        "# y label\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel('True Positive rate', fontsize=14)\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('ROC',dpi=300)\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "hWfi5wqBEgNG",
        "outputId": "d271c249-736f-4486-8508-81546cd5f493"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WvpmdasUGxJk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}